{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0\n",
      " 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 0 1 0 0 1 1 0 1 1\n",
      " 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from fast_cubic_smpa import FastCubicSMPA\n",
    "import numpy as np\n",
    "\n",
    "# Your data\n",
    "X = np.random.rand(100, 3)\n",
    "y = (X[:, 0] + X[:, 1] > 1).astype(int)\n",
    "\n",
    "model = FastCubicSMPA(n_control_points=6, max_iter=50)\n",
    "model.fit(X, y)\n",
    "preds = model.predict(X)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv(\"./Datasets/diabetes.csv\")\n",
    "train_df, test_df = train_test_split(diabetes_df, test_size = 0.3, random_state = 25)\n",
    "X_train = train_df.drop(\"Outcome\", axis = 1)\n",
    "y_train = train_df[\"Outcome\"]\n",
    "X_test = test_df.drop(\"Outcome\", axis = 1)\n",
    "y_test = test_df[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.   , 134.   ,  74.   , ...,  25.9  ,   0.46 ,  81.   ],\n",
       "       [  4.   , 111.   ,  72.   , ...,  37.1  ,   1.39 ,  56.   ],\n",
       "       [  8.   ,  95.   ,  72.   , ...,  36.8  ,   0.485,  57.   ],\n",
       "       ...,\n",
       "       [ 10.   , 162.   ,  84.   , ...,  27.7  ,   0.182,  54.   ],\n",
       "       [  0.   ,  93.   , 100.   , ...,  43.4  ,   1.021,  35.   ],\n",
       "       [  6.   , 123.   ,  72.   , ...,  33.6  ,   0.733,  34.   ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.to_numpy()\n",
    "X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_least_correlated_feature(X, standardize=True, feature_order=None):\n",
    "    \"\"\"\n",
    "    Reorder X based on correlation or a provided feature order.\n",
    "\n",
    "    Parameters:\n",
    "    - X: numpy array or pandas DataFrame\n",
    "    - standardize: bool\n",
    "    - feature_order: list, optional order from training set (default: None, compute from X)\n",
    "\n",
    "    Returns:\n",
    "    - X_reordered, feature_order (if computed)\n",
    "    \"\"\"\n",
    "    is_dataframe = isinstance(X, pd.DataFrame)\n",
    "    if is_dataframe:\n",
    "        column_names = X.columns\n",
    "        X_np = X.to_numpy()\n",
    "    else:\n",
    "        X_np = np.asarray(X)\n",
    "\n",
    "    if feature_order is None:\n",
    "        if standardize:\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X_np)\n",
    "        else:\n",
    "            X_scaled = X_np.copy()\n",
    "\n",
    "        corr_matrix = np.abs(np.corrcoef(X_scaled, rowvar=False))\n",
    "        n_features = X_np.shape[1]\n",
    "        avg_corr = (np.sum(corr_matrix, axis=1) - np.diag(corr_matrix)) / (n_features - 1)\n",
    "        target_idx = np.argmin(avg_corr)\n",
    "        feature_order = list(range(n_features))\n",
    "        feature_order.pop(target_idx)\n",
    "        feature_order.append(target_idx)\n",
    "\n",
    "    if is_dataframe:\n",
    "        X_reordered = X.iloc[:, feature_order]\n",
    "    else:\n",
    "        X_reordered = X_np[:, feature_order]\n",
    "\n",
    "    return X_reordered, feature_order\n",
    "\n",
    "# Usage\n",
    "X_train_reordered, feature_order = reorder_least_correlated_feature(X_train)\n",
    "X_test_reordered, _ = reorder_least_correlated_feature(X_test, feature_order=feature_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_reordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(X, y):\n",
    "    param_grid = {\n",
    "        'n_control_points': [6, 9, 12, 15],  # Test your higher values\n",
    "        'max_iter': [200, 500, 1000],        # More iterations\n",
    "        'lambda_reg': [1e-6, 1e-4, 1e-2]    # Include very low regularization\n",
    "    }\n",
    "\n",
    "    base_model = FastCubicSMPA(verbose=False)\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='accuracy',  # Switch to accuracy to match your 71% target\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    grid_search.fit(X, y)\n",
    "    fit_time = time.time() - start_time\n",
    "\n",
    "    print(\"\\nGrid Search Results:\")\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV Accuracy: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Total Fit Time: {fit_time:.2f} seconds\")\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    preds = best_model.predict(X)\n",
    "    print(\"\\nClassification Report on Full Dataset:\")\n",
    "    print(classification_report(y, preds))\n",
    "\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<fast_cubic_smpa.FastCubicSMPA object at 0x7b35c37a88f0>' (type <class 'fast_cubic_smpa.FastCubicSMPA'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_grid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_reordered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 20\u001b[0m, in \u001b[0;36mrun_grid_search\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      9\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     10\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mbase_model,\n\u001b[1;32m     11\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 20\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGrid Search Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/mise/installs/python/latest/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/mise/installs/python/latest/lib/python3.12/site-packages/sklearn/model_selection/_search.py:936\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    933\u001b[0m cv_orig \u001b[38;5;241m=\u001b[39m check_cv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv, y, classifier\u001b[38;5;241m=\u001b[39mis_classifier(estimator))\n\u001b[1;32m    934\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m cv_orig\u001b[38;5;241m.\u001b[39mget_n_splits(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)\n\u001b[0;32m--> 936\u001b[0m base_estimator \u001b[38;5;241m=\u001b[39m \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, pre_dispatch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_dispatch)\n\u001b[1;32m    940\u001b[0m fit_and_score_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    941\u001b[0m     scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[1;32m    942\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    949\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    950\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/mise/installs/python/latest/lib/python3.12/site-packages/sklearn/base.py:95\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_clone__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(estimator):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39m__sklearn_clone__()\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_parametrized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/mise/installs/python/latest/lib/python3.12/site-packages/sklearn/base.py:117\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    112\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot clone object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m                 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should provide an instance of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m                 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn estimator instead of a class.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m             )\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    118\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot clone object \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit does not seem to be a scikit-learn \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator as it does not implement a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mrepr\u001b[39m(estimator), \u001b[38;5;28mtype\u001b[39m(estimator))\n\u001b[1;32m    122\u001b[0m             )\n\u001b[1;32m    124\u001b[0m klass \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[1;32m    125\u001b[0m new_object_params \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot clone object '<fast_cubic_smpa.FastCubicSMPA object at 0x7b35c37a88f0>' (type <class 'fast_cubic_smpa.FastCubicSMPA'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "run_grid_search(X_train_reordered, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
