{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class OptimizedBSpline(nn.Module):\n",
    "    \"\"\"Optimized B-spline with iterative De Boor algorithm\"\"\"\n",
    "    def __init__(self, knots, degree=3):\n",
    "        super().__init__()\n",
    "        self.knots = knots\n",
    "        self.degree = degree\n",
    "        self.n_knots = len(knots)\n",
    "\n",
    "    def _find_interval(self, t):\n",
    "        t_clamped = torch.clamp(t, self.knots[self.degree], self.knots[self.n_knots - self.degree - 1])\n",
    "        i = torch.searchsorted(self.knots, t_clamped, right=True) - 1\n",
    "        return torch.clamp(i, self.degree, self.n_knots - self.degree - 1)\n",
    "\n",
    "    def forward(self, t, control_points):\n",
    "        batch_size = t.shape[0]\n",
    "        n_control = len(control_points)\n",
    "        k = self.degree\n",
    "        interval = self._find_interval(t)\n",
    "        d = torch.zeros(batch_size, k + 1, device=t.device, dtype=t.dtype)\n",
    "        for j in range(k + 1):\n",
    "            idx = torch.clamp(interval - k + j, 0, n_control - 1)\n",
    "            d[:, j] = control_points[idx]\n",
    "        for r in range(1, k + 1):\n",
    "            for j in range(k, r - 1, -1):\n",
    "                left_knot = self.knots[interval - k + j]\n",
    "                right_knot = self.knots[interval - k + j + r]\n",
    "                alpha = (t - left_knot) / (right_knot - left_knot + 1e-8)\n",
    "                d[:, j] = (1 - alpha) * d[:, j - 1] + alpha * d[:, j]\n",
    "        return d[:, k]\n",
    "\n",
    "class OptimizedTorchCubicSpline(nn.Module):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.y = nn.Parameter(y)\n",
    "        n = len(x)\n",
    "        self.register_buffer('knots', torch.cat([x[0].repeat(3), x[1:-1], x[-1].repeat(3)]))\n",
    "        self.bspline = OptimizedBSpline(self.knots, degree=3)\n",
    "        self.x_min = x[0]\n",
    "        self.x_max = x[-1]\n",
    "\n",
    "    def forward(self, t):\n",
    "        return self.bspline(torch.clamp(t, self.x_min, self.x_max), self.y)\n",
    "\n",
    "class OptimizedDifferentiablePchip(nn.Module):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.y = nn.Parameter(y)\n",
    "        self.n = len(x) - 1\n",
    "\n",
    "    def _compute_derivatives(self, y):\n",
    "        dy = y[1:] - y[:-1]\n",
    "        dx = self.x[1:] - self.x[:-1]\n",
    "        slopes = dy / dx\n",
    "        d = torch.zeros_like(y)\n",
    "        for i in range(1, len(y)-1):\n",
    "            if slopes[i-1] * slopes[i] > 0:\n",
    "                w1 = 2*dx[i] + dx[i-1]\n",
    "                w2 = dx[i] + 2*dx[i-1]\n",
    "                d[i] = (w1 + w2) / (w1/slopes[i-1] + w2/slopes[i])\n",
    "        d[0] = slopes[0]\n",
    "        d[-1] = slopes[-1]\n",
    "        return d\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = t.contiguous()\n",
    "        idx = torch.clamp(torch.searchsorted(self.x, t) - 1, 0, self.n - 1)\n",
    "        x0 = self.x[idx]\n",
    "        x1 = self.x[idx + 1]\n",
    "        y0 = self.y[idx]\n",
    "        y1 = self.y[idx + 1]\n",
    "        t_norm = (t - x0) / (x1 - x0)\n",
    "        d = self._compute_derivatives(self.y)\n",
    "        d0 = d[idx]\n",
    "        d1 = d[idx + 1]\n",
    "        t2 = t_norm * t_norm\n",
    "        t3 = t2 * t_norm\n",
    "        h00 = 2*t3 - 3*t2 + 1\n",
    "        h10 = t3 - 2*t2 + t_norm\n",
    "        h01 = -2*t3 + 3*t2\n",
    "        h11 = t3 - t2\n",
    "        dx_segment = x1 - x0\n",
    "        return h00 * y0 + h10 * dx_segment * d0 + h01 * y1 + h11 * dx_segment * d1\n",
    "\n",
    "class OptimizedPyTorchGradientSMPA(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, learning_rate=0.05, epochs=200, random_state=7, verbose=False,\n",
    "                 lambda_reg=0.0001, patience=10, decay_factor=0.9, min_learning_rate=1e-6,\n",
    "                 n_control_points=6, smoothing_factor=0.0001, spline_type='cubic',\n",
    "                 device=None, track_history=False, optimizer_type='adam',\n",
    "                 scheduler_type='reduce_on_plateau', weight_reg=0.001, weight_l1=1e-5):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.initial_learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.patience = patience\n",
    "        self.decay_factor = decay_factor\n",
    "        self.min_learning_rate = min_learning_rate\n",
    "        self.n_control_points = n_control_points\n",
    "        self.smoothing_factor = smoothing_factor\n",
    "        self.spline_type = spline_type\n",
    "        self.device = device if device is not None else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.track_history = track_history\n",
    "        self.optimizer_type = optimizer_type\n",
    "        self.scheduler_type = scheduler_type\n",
    "        self.weight_reg = weight_reg\n",
    "        self.weight_l1 = weight_l1\n",
    "        if spline_type not in ['cubic', 'pchip']:\n",
    "            raise ValueError(\"spline_type must be 'cubic' or 'pchip'\")\n",
    "        torch.manual_seed(random_state)\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    def _to_tensor(self, data, dtype=torch.float32):\n",
    "        if isinstance(data, torch.Tensor):\n",
    "            return data.to(self.device, dtype=dtype, non_blocking=True)\n",
    "        return torch.tensor(data, dtype=dtype, device=self.device)\n",
    "\n",
    "    def _calculate_class_means(self, X, y):\n",
    "        mask_1 = y == 1\n",
    "        self.m1 = torch.mean(X[mask_1], dim=0)\n",
    "        self.m0 = torch.mean(X[~mask_1], dim=0)\n",
    "\n",
    "    def _initialize_control_points(self, X):\n",
    "        n_features = X.shape[1] - 1\n",
    "        self.spline_models = nn.ModuleList()\n",
    "        self.feature_scales = [X[:, i].abs().max().item() + 1e-8 for i in range(n_features)]\n",
    "        for i in range(n_features):\n",
    "            x_min, x_max = X[:, i].min().item(), X[:, i].max().item()\n",
    "            control_x = torch.linspace(x_min, x_max, self.n_control_points, device=self.device)\n",
    "            y_min, y_max = X[:, -1].min().item(), X[:, -1].max().item()\n",
    "            y_mid = (self.m0[-1] + self.m1[-1]) / 2\n",
    "            y_range = y_max - y_min\n",
    "            control_y = torch.empty(self.n_control_points, device=self.device).uniform_(\n",
    "                y_mid - y_range * 0.5, y_mid + y_range * 0.5\n",
    "            )\n",
    "            if self.spline_type == 'cubic':\n",
    "                spline = OptimizedTorchCubicSpline(control_x, control_y).to(self.device)\n",
    "            else:\n",
    "                spline = OptimizedDifferentiablePchip(control_x, control_y).to(self.device)\n",
    "            self.spline_models.append(spline)\n",
    "        self.weights = nn.Parameter(torch.full((n_features,), 0.5, device=self.device))\n",
    "        self.initial_control_points = [(m.x.clone(), m.y.clone()) for m in self.spline_models]\n",
    "\n",
    "    def _calculate_displacement(self, X):\n",
    "        product = torch.ones(X.shape[0], device=X.device, dtype=X.dtype)\n",
    "        for i, (w, spline) in enumerate(zip(self.weights, self.spline_models)):\n",
    "            spline_output = spline(X[:, i])\n",
    "            normalized_output = spline_output / self.feature_scales[i]\n",
    "            product *= (1 + w * normalized_output)\n",
    "        return X[:, -1] - product\n",
    "\n",
    "    def _update_pseudo_labels(self, X, y):\n",
    "        m1_displacement = self._calculate_displacement(self.m1.unsqueeze(0))[0]\n",
    "        self.class_1_pseudo = 1 if m1_displacement > 0 else -1\n",
    "        self.class_0_pseudo = -self.class_1_pseudo\n",
    "        return torch.where(y == 1, self.class_1_pseudo, self.class_0_pseudo)\n",
    "\n",
    "    def _create_optimizer_and_scheduler(self):\n",
    "        params = [p for spline in self.spline_models for p in spline.parameters()] + [self.weights]\n",
    "        if self.optimizer_type.lower() == 'adam':\n",
    "            optimizer = torch.optim.Adam(params, lr=self.initial_learning_rate)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(params, lr=self.initial_learning_rate)\n",
    "        if self.scheduler_type.lower() == 'reduce_on_plateau':\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode='min', factor=self.decay_factor,\n",
    "                patience=self.patience, min_lr=self.min_learning_rate)\n",
    "        else:\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "                optimizer, step_size=self.patience, gamma=self.decay_factor\n",
    "            )\n",
    "        return optimizer, scheduler\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        try:\n",
    "            l = np.unique(y)\n",
    "            if len(l) != 2:\n",
    "                raise ValueError(\"Algorithm for binary classification only.\")\n",
    "            if X.shape[1] < 2:\n",
    "                raise ValueError(\"At least 2 features required\")\n",
    "\n",
    "            self.label_mapping = {l[0]: 0, l[1]: 1}\n",
    "            y = np.where(y == l[0], 0, 1)\n",
    "\n",
    "            X_tensor = self._to_tensor(X)\n",
    "            y_tensor = self._to_tensor(y, dtype=torch.long)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                self._calculate_class_means(X_tensor, y_tensor)\n",
    "                self._initialize_control_points(X_tensor)\n",
    "\n",
    "            optimizer, scheduler = self._create_optimizer_and_scheduler()\n",
    "\n",
    "            best_error = float('inf')\n",
    "            best_control_ys = [spline.y.clone() for spline in self.spline_models]\n",
    "            best_weights = self.weights.clone()\n",
    "            best_class_1_pseudo = None\n",
    "\n",
    "            if self.track_history:\n",
    "                self.error_history_ = []\n",
    "                self.control_point_history = [self.initial_control_points]\n",
    "\n",
    "            for epoch in range(self.epochs):\n",
    "                pseudo_labels = self._update_pseudo_labels(X_tensor, y_tensor)\n",
    "                displacements = self._calculate_displacement(X_tensor)\n",
    "\n",
    "                errors = displacements * pseudo_labels <= 0\n",
    "                error_count = errors.sum().item()\n",
    "\n",
    "                if self.verbose and epoch % 5 == 0:\n",
    "                    current_lr = optimizer.param_groups[0]['lr']\n",
    "                    product = torch.ones(X_tensor.shape[0], device=X_tensor.device)\n",
    "                    for i, (w, spline) in enumerate(zip(self.weights, self.spline_models)):\n",
    "                        spline_output = spline(X_tensor[:, i])\n",
    "                        normalized_output = spline_output / self.feature_scales[i]\n",
    "                        product *= (1 + w * normalized_output)\n",
    "                    print(f\"Epoch {epoch}: Errors = {error_count}, LR = {current_lr:.6f}\")\n",
    "                    print(f\"  Mean product: {product.mean().item():.4f}, \"\n",
    "                          f\"Mean displacement: {displacements.mean().item():.4f}, \"\n",
    "                          f\"Weights mean: {self.weights.mean().item():.4f}, \"\n",
    "                          f\"Weights std: {self.weights.std().item():.4f}\")\n",
    "\n",
    "                if error_count < best_error:\n",
    "                    best_error = error_count\n",
    "                    best_control_ys = [spline.y.clone() for spline in self.spline_models]\n",
    "                    best_weights = self.weights.clone()\n",
    "                    best_class_1_pseudo = self.class_1_pseudo\n",
    "                    self.best_epoch = epoch\n",
    "                    if error_count == 0 and epoch > 10:\n",
    "                        if self.verbose:\n",
    "                            print(f\"Perfect separation achieved at epoch {epoch}\")\n",
    "                        break\n",
    "\n",
    "                if self.track_history:\n",
    "                    self.error_history_.append(error_count)\n",
    "                    self.control_point_history.append(\n",
    "                        [(s.x.clone().cpu().numpy(), s.y.clone().detach().cpu().numpy())\n",
    "                         for s in self.spline_models]\n",
    "                    )\n",
    "\n",
    "                if error_count == 0:\n",
    "                    continue\n",
    "\n",
    "                error_indices = torch.where(errors)[0]\n",
    "                if len(error_indices) == 0:\n",
    "                    continue\n",
    "                X_err = X_tensor[error_indices]\n",
    "                y_err = y_tensor[error_indices]\n",
    "                ti = torch.where(y_err == 1, 1, -1)\n",
    "\n",
    "                product = torch.ones(X_err.shape[0], device=X_err.device, dtype=X_err.dtype)\n",
    "                for i, (w, spline) in enumerate(zip(self.weights, self.spline_models)):\n",
    "                    spline_output = spline(X_err[:, i])\n",
    "                    normalized_output = spline_output / self.feature_scales[i]\n",
    "                    product *= (1 + w * normalized_output)\n",
    "                loss = torch.mean(torch.relu(1.0 - ti * self.class_1_pseudo * (X_err[:, -1] - product)))\n",
    "\n",
    "                if self.lambda_reg > 0:\n",
    "                    smoothness_penalty = 0\n",
    "                    for spline in self.spline_models:\n",
    "                        y_diff = spline.y[1:] - spline.y[:-1]\n",
    "                        x_diff = spline.x[1:] - spline.x[:-1]\n",
    "                        smoothness_penalty += torch.mean((y_diff / (x_diff + 1e-8))**2)\n",
    "                    loss += self.lambda_reg * smoothness_penalty\n",
    "                if self.weight_reg > 0:\n",
    "                    weight_penalty = torch.sum(self.weights ** 2)\n",
    "                    loss += self.weight_reg * weight_penalty\n",
    "                if self.weight_l1 > 0:\n",
    "                    weight_l1_penalty = torch.sum(torch.abs(self.weights))\n",
    "                    loss += self.weight_l1 * weight_l1_penalty\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    [p for spline in self.spline_models for p in spline.parameters()] + [self.weights],\n",
    "                    max_norm=10.0\n",
    "                )\n",
    "                if epoch % 5 == 0 and self.verbose:\n",
    "                    for i, spline in enumerate(self.spline_models[:3]):  # Limit to 3 for brevity\n",
    "                        grad_norm = torch.norm(spline.y.grad) if spline.y.grad is not None else 0\n",
    "                        print(f\"  Spline {i} grad norm: {grad_norm:.4f}\")\n",
    "                    print(f\"  Weights grad norm: {torch.norm(self.weights.grad):.4f}\")\n",
    "                optimizer.step()\n",
    "\n",
    "                if scheduler is not None:\n",
    "                    if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                        scheduler.step(error_count)\n",
    "                    else:\n",
    "                        scheduler.step()\n",
    "                    if optimizer.param_groups[0]['lr'] <= self.min_learning_rate:\n",
    "                        if self.verbose:\n",
    "                            print(f\"Minimum learning rate reached at epoch {epoch}\")\n",
    "                        break\n",
    "\n",
    "            for spline, best_y in zip(self.spline_models, best_control_ys):\n",
    "                spline.y.data = best_y\n",
    "            self.weights.data = best_weights\n",
    "            self.class_1_pseudo = best_class_1_pseudo\n",
    "        except Exception as e:\n",
    "            print(f\"Error in SMPA fit: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            raise\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_tensor = self._to_tensor(X)\n",
    "        displacements = self._calculate_displacement(X_tensor)\n",
    "        predictions = torch.where(displacements > 0,\n",
    "                                torch.tensor(1 if self.class_1_pseudo > 0 else 0, device=self.device),\n",
    "                                torch.tensor(0 if self.class_1_pseudo > 0 else 1, device=self.device))\n",
    "        pred_numpy = predictions.cpu().numpy()\n",
    "        reverse_mapping = {v: k for k, v in self.label_mapping.items()}\n",
    "        original_predictions = np.array([reverse_mapping[p] for p in pred_numpy])\n",
    "        return original_predictions\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_tensor = self._to_tensor(X)\n",
    "        displacements = self._calculate_displacement(X_tensor)\n",
    "        raw_probs = 1 / (1 + torch.exp(-displacements * self.class_1_pseudo * 0.5))\n",
    "        if self.class_1_pseudo > 0:\n",
    "            probs = torch.column_stack([1 - raw_probs, raw_probs])\n",
    "        else:\n",
    "            probs = torch.column_stack([raw_probs, 1 - raw_probs])\n",
    "        return probs.cpu().detach().numpy()\n",
    "\n",
    "    def plot_convergence(self, figsize=(10, 4)):\n",
    "        if not self.track_history or not hasattr(self, 'error_history_'):\n",
    "            print(\"Convergence plotting requires track_history=True and a fitted model.\")\n",
    "            return None\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax.plot(self.error_history_, 'b-', label='Errors')\n",
    "        ax.set_title('Error Convergence')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Number of Errors')\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000, 4)\n",
      "y shape: (1000,)\n",
      "Class balance: [500 500]\n",
      "X[:, -1] range: -1.9276860663104305 1.9406380647122043\n",
      "Feature ranges: [-0.99963016 -0.99710631 -0.99588175] [0.99946603 0.99601529 0.9995589 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_toy_dataset(n_samples=1000, random_state=7):\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Generate 3 predictive features\n",
    "    x1 = np.random.uniform(-1, 1, n_samples)\n",
    "    x2 = np.random.uniform(-1, 1, n_samples)\n",
    "    x3 = np.random.uniform(-1, 1, n_samples)\n",
    "\n",
    "    # Compute response variable with interactions and non-linearity\n",
    "    X_last = x1 * x2 + np.sin(np.pi * x3) + np.random.normal(0, 0.1, n_samples)\n",
    "\n",
    "    # Combine into feature matrix (x1, x2, x3, X_last)\n",
    "    X = np.column_stack([x1, x2, x3, X_last])\n",
    "\n",
    "    # Generate labels based on X_last threshold (median for balanced classes)\n",
    "    threshold = np.median(X_last)\n",
    "    y = (X_last > threshold).astype(int)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Generate dataset\n",
    "X, y = generate_toy_dataset(n_samples=1000, random_state=7)\n",
    "\n",
    "# Verify dataset\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Class balance:\", np.bincount(y))\n",
    "print(\"X[:, -1] range:\", X[:, -1].min(), X[:, -1].max())\n",
    "print(\"Feature ranges:\", X[:, :-1].min(axis=0), X[:, :-1].max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Filtered 0 zero-variance features\n"
     ]
    }
   ],
   "source": [
    "def reorder_least_correlated_feature(X, standardize=True, feature_order=None, scaler=None, valid_mask=None):\n",
    "    X_np = np.asarray(X)\n",
    "    if valid_mask is None:  # Train: compute mask\n",
    "        variances = np.var(X_np, axis=0)\n",
    "        valid_mask = variances > 0\n",
    "        print(f\"Train: Filtered {np.sum(~valid_mask)} zero-variance features\")\n",
    "    X_np = X_np[:, valid_mask]  # Apply mask to both train and test\n",
    "\n",
    "    if feature_order is None:  # Train\n",
    "        if standardize:\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X_np)\n",
    "        else:\n",
    "            X_scaled = X_np.copy()\n",
    "        corr_matrix = np.abs(np.corrcoef(X_scaled, rowvar=False))\n",
    "        n_features = X_scaled.shape[1]\n",
    "        avg_corr = (np.sum(corr_matrix, axis=1) - np.diag(corr_matrix)) / (n_features - 1)\n",
    "        target_idx = np.argmin(avg_corr)\n",
    "        feature_order = list(range(n_features))\n",
    "        feature_order.pop(target_idx)\n",
    "        feature_order.append(target_idx)\n",
    "        X_reordered = X_scaled[:, feature_order]\n",
    "    else:  # Test\n",
    "        if standardize and scaler is not None:\n",
    "            X_scaled = scaler.transform(X_np)  # Now same # of features\n",
    "            X_reordered = X_scaled[:, feature_order]\n",
    "        else:\n",
    "            X_reordered = X_np[:, feature_order]\n",
    "    return X_reordered, feature_order, scaler, valid_mask\n",
    "\n",
    "# Apply with consistent mask\n",
    "X_train_reordered, feature_order, scaler, valid_mask = reorder_least_correlated_feature(X_train, standardize=True)\n",
    "X_test_reordered, _, _, _ = reorder_least_correlated_feature(X_test, standardize=True, feature_order=feature_order, scaler=scaler, valid_mask=valid_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Errors = 346, LR = 0.010000\n",
      "  Mean product: 0.9929, Mean displacement: -0.9929, Weights mean: 0.5000, Weights std: 0.0000\n",
      "  Spline 0 grad norm: 0.0676\n",
      "  Spline 1 grad norm: 0.1131\n",
      "  Spline 2 grad norm: 0.1064\n",
      "  Weights grad norm: 0.1706\n",
      "Epoch 5: Errors = 338, LR = 0.010000\n",
      "  Mean product: 0.9761, Mean displacement: -0.9761, Weights mean: 0.5501, Weights std: 0.0000\n",
      "  Spline 0 grad norm: 0.0730\n",
      "  Spline 1 grad norm: 0.1195\n",
      "  Spline 2 grad norm: 0.1136\n",
      "  Weights grad norm: 0.1867\n",
      "Epoch 10: Errors = 324, LR = 0.010000\n",
      "  Mean product: 0.9550, Mean displacement: -0.9550, Weights mean: 0.6007, Weights std: 0.0003\n",
      "  Spline 0 grad norm: 0.0735\n",
      "  Spline 1 grad norm: 0.1223\n",
      "  Spline 2 grad norm: 0.1180\n",
      "  Weights grad norm: 0.1986\n",
      "Epoch 15: Errors = 321, LR = 0.010000\n",
      "  Mean product: 0.9293, Mean displacement: -0.9293, Weights mean: 0.6517, Weights std: 0.0012\n",
      "  Spline 0 grad norm: 0.0703\n",
      "  Spline 1 grad norm: 0.1229\n",
      "  Spline 2 grad norm: 0.1362\n",
      "  Weights grad norm: 0.2077\n",
      "Epoch 20: Errors = 309, LR = 0.010000\n",
      "  Mean product: 0.9017, Mean displacement: -0.9017, Weights mean: 0.7033, Weights std: 0.0031\n",
      "  Spline 0 grad norm: 0.0681\n",
      "  Spline 1 grad norm: 0.1235\n",
      "  Spline 2 grad norm: 0.1347\n",
      "  Weights grad norm: 0.2179\n",
      "Epoch 25: Errors = 301, LR = 0.010000\n",
      "  Mean product: 0.8748, Mean displacement: -0.8748, Weights mean: 0.7550, Weights std: 0.0062\n",
      "  Spline 0 grad norm: 0.0629\n",
      "  Spline 1 grad norm: 0.1212\n",
      "  Spline 2 grad norm: 0.1320\n",
      "  Weights grad norm: 0.2227\n",
      "Epoch 30: Errors = 297, LR = 0.010000\n",
      "  Mean product: 0.8506, Mean displacement: -0.8506, Weights mean: 0.8065, Weights std: 0.0108\n",
      "  Spline 0 grad norm: 0.0569\n",
      "  Spline 1 grad norm: 0.1182\n",
      "  Spline 2 grad norm: 0.1285\n",
      "  Weights grad norm: 0.2254\n",
      "Epoch 35: Errors = 296, LR = 0.010000\n",
      "  Mean product: 0.8308, Mean displacement: -0.8308, Weights mean: 0.8565, Weights std: 0.0186\n",
      "  Spline 0 grad norm: 0.0493\n",
      "  Spline 1 grad norm: 0.1135\n",
      "  Spline 2 grad norm: 0.1241\n",
      "  Weights grad norm: 0.2239\n",
      "Epoch 40: Errors = 288, LR = 0.010000\n",
      "  Mean product: 0.8190, Mean displacement: -0.8190, Weights mean: 0.9027, Weights std: 0.0327\n",
      "  Spline 0 grad norm: 0.0457\n",
      "  Spline 1 grad norm: 0.1095\n",
      "  Spline 2 grad norm: 0.1187\n",
      "  Weights grad norm: 0.2195\n",
      "Epoch 45: Errors = 282, LR = 0.010000\n",
      "  Mean product: 0.8179, Mean displacement: -0.8179, Weights mean: 0.9425, Weights std: 0.0571\n",
      "  Spline 0 grad norm: 0.0413\n",
      "  Spline 1 grad norm: 0.1054\n",
      "  Spline 2 grad norm: 0.1156\n",
      "  Weights grad norm: 0.2179\n",
      "Epoch 50: Errors = 276, LR = 0.010000\n",
      "  Mean product: 0.8320, Mean displacement: -0.8320, Weights mean: 0.9754, Weights std: 0.0923\n",
      "  Spline 0 grad norm: 0.0378\n",
      "  Spline 1 grad norm: 0.1019\n",
      "  Spline 2 grad norm: 0.1149\n",
      "  Weights grad norm: 0.2170\n",
      "Epoch 55: Errors = 268, LR = 0.010000\n",
      "  Mean product: 0.8623, Mean displacement: -0.8623, Weights mean: 1.0026, Weights std: 0.1364\n",
      "  Spline 0 grad norm: 0.0309\n",
      "  Spline 1 grad norm: 0.0990\n",
      "  Spline 2 grad norm: 0.1148\n",
      "  Weights grad norm: 0.2137\n",
      "Epoch 60: Errors = 261, LR = 0.010000\n",
      "  Mean product: 0.9048, Mean displacement: -0.9048, Weights mean: 1.0269, Weights std: 0.1843\n",
      "  Spline 0 grad norm: 0.0256\n",
      "  Spline 1 grad norm: 0.0948\n",
      "  Spline 2 grad norm: 0.1152\n",
      "  Weights grad norm: 0.2106\n",
      "Epoch 65: Errors = 253, LR = 0.010000\n",
      "  Mean product: 0.9559, Mean displacement: -0.9559, Weights mean: 1.0498, Weights std: 0.2330\n",
      "  Spline 0 grad norm: 0.0190\n",
      "  Spline 1 grad norm: 0.0890\n",
      "  Spline 2 grad norm: 0.1134\n",
      "  Weights grad norm: 0.1993\n",
      "Epoch 70: Errors = 249, LR = 0.010000\n",
      "  Mean product: 1.0074, Mean displacement: -1.0074, Weights mean: 1.0736, Weights std: 0.2780\n",
      "  Spline 0 grad norm: 0.0148\n",
      "  Spline 1 grad norm: 0.0816\n",
      "  Spline 2 grad norm: 0.1117\n",
      "  Weights grad norm: 0.1909\n",
      "Epoch 75: Errors = 240, LR = 0.010000\n",
      "  Mean product: 1.0524, Mean displacement: -1.0524, Weights mean: 1.0996, Weights std: 0.3153\n",
      "  Spline 0 grad norm: 0.0141\n",
      "  Spline 1 grad norm: 0.0733\n",
      "  Spline 2 grad norm: 0.1107\n",
      "  Weights grad norm: 0.1817\n",
      "Epoch 80: Errors = 238, LR = 0.010000\n",
      "  Mean product: 1.0894, Mean displacement: -1.0894, Weights mean: 1.1273, Weights std: 0.3452\n",
      "  Spline 0 grad norm: 0.0135\n",
      "  Spline 1 grad norm: 0.0620\n",
      "  Spline 2 grad norm: 0.1055\n",
      "  Weights grad norm: 0.1701\n",
      "Epoch 85: Errors = 232, LR = 0.010000\n",
      "  Mean product: 1.1294, Mean displacement: -1.1294, Weights mean: 1.1525, Weights std: 0.3746\n",
      "  Spline 0 grad norm: 0.0107\n",
      "  Spline 1 grad norm: 0.0493\n",
      "  Spline 2 grad norm: 0.1007\n",
      "  Weights grad norm: 0.1551\n",
      "Epoch 90: Errors = 230, LR = 0.010000\n",
      "  Mean product: 1.1655, Mean displacement: -1.1655, Weights mean: 1.1771, Weights std: 0.3991\n",
      "  Spline 0 grad norm: 0.0095\n",
      "  Spline 1 grad norm: 0.0363\n",
      "  Spline 2 grad norm: 0.0971\n",
      "  Weights grad norm: 0.1464\n",
      "Epoch 95: Errors = 227, LR = 0.010000\n",
      "  Mean product: 1.2002, Mean displacement: -1.2002, Weights mean: 1.1998, Weights std: 0.4208\n",
      "  Spline 0 grad norm: 0.0107\n",
      "  Spline 1 grad norm: 0.0230\n",
      "  Spline 2 grad norm: 0.0930\n",
      "  Weights grad norm: 0.1375\n",
      "Epoch 100: Errors = 224, LR = 0.010000\n",
      "  Mean product: 1.2355, Mean displacement: -1.2355, Weights mean: 1.2191, Weights std: 0.4419\n",
      "  Spline 0 grad norm: 0.0068\n",
      "  Spline 1 grad norm: 0.0116\n",
      "  Spline 2 grad norm: 0.0942\n",
      "  Weights grad norm: 0.1330\n",
      "Epoch 105: Errors = 225, LR = 0.010000\n",
      "  Mean product: 1.2680, Mean displacement: -1.2680, Weights mean: 1.2351, Weights std: 0.4618\n",
      "  Spline 0 grad norm: 0.0089\n",
      "  Spline 1 grad norm: 0.0154\n",
      "  Spline 2 grad norm: 0.0909\n",
      "  Weights grad norm: 0.1306\n",
      "Epoch 110: Errors = 223, LR = 0.009000\n",
      "  Mean product: 1.3064, Mean displacement: -1.3064, Weights mean: 1.2449, Weights std: 0.4848\n",
      "  Spline 0 grad norm: 0.0114\n",
      "  Spline 1 grad norm: 0.0301\n",
      "  Spline 2 grad norm: 0.0934\n",
      "  Weights grad norm: 0.1355\n",
      "Epoch 115: Errors = 219, LR = 0.009000\n",
      "  Mean product: 1.3483, Mean displacement: -1.3483, Weights mean: 1.2485, Weights std: 0.5095\n",
      "  Spline 0 grad norm: 0.0063\n",
      "  Spline 1 grad norm: 0.0435\n",
      "  Spline 2 grad norm: 0.1009\n",
      "  Weights grad norm: 0.1469\n",
      "Epoch 120: Errors = 217, LR = 0.009000\n",
      "  Mean product: 1.3835, Mean displacement: -1.3835, Weights mean: 1.2500, Weights std: 0.5329\n",
      "  Spline 0 grad norm: 0.0092\n",
      "  Spline 1 grad norm: 0.0590\n",
      "  Spline 2 grad norm: 0.1076\n",
      "  Weights grad norm: 0.1612\n",
      "Epoch 125: Errors = 214, LR = 0.009000\n",
      "  Mean product: 1.4167, Mean displacement: -1.4167, Weights mean: 1.2480, Weights std: 0.5589\n",
      "  Spline 0 grad norm: 0.0106\n",
      "  Spline 1 grad norm: 0.0751\n",
      "  Spline 2 grad norm: 0.1193\n",
      "  Weights grad norm: 0.1814\n",
      "Epoch 130: Errors = 213, LR = 0.009000\n",
      "  Mean product: 1.4496, Mean displacement: -1.4496, Weights mean: 1.2417, Weights std: 0.5902\n",
      "  Spline 0 grad norm: 0.0146\n",
      "  Spline 1 grad norm: 0.0926\n",
      "  Spline 2 grad norm: 0.1325\n",
      "  Weights grad norm: 0.2067\n",
      "Epoch 135: Errors = 208, LR = 0.009000\n",
      "  Mean product: 1.4853, Mean displacement: -1.4853, Weights mean: 1.2299, Weights std: 0.6303\n",
      "  Spline 0 grad norm: 0.0151\n",
      "  Spline 1 grad norm: 0.1117\n",
      "  Spline 2 grad norm: 0.1557\n",
      "  Weights grad norm: 0.2435\n",
      "Epoch 140: Errors = 207, LR = 0.009000\n",
      "  Mean product: 1.5192, Mean displacement: -1.5192, Weights mean: 1.2130, Weights std: 0.6798\n",
      "  Spline 0 grad norm: 0.0198\n",
      "  Spline 1 grad norm: 0.1349\n",
      "  Spline 2 grad norm: 0.1792\n",
      "  Weights grad norm: 0.2860\n",
      "Epoch 145: Errors = 199, LR = 0.009000\n",
      "  Mean product: 1.5572, Mean displacement: -1.5572, Weights mean: 1.1898, Weights std: 0.7425\n",
      "  Spline 0 grad norm: 0.0228\n",
      "  Spline 1 grad norm: 0.1604\n",
      "  Spline 2 grad norm: 0.2084\n",
      "  Weights grad norm: 0.3368\n",
      "Epoch 150: Errors = 191, LR = 0.009000\n",
      "  Mean product: 1.5942, Mean displacement: -1.5942, Weights mean: 1.1614, Weights std: 0.8173\n",
      "  Spline 0 grad norm: 0.0235\n",
      "  Spline 1 grad norm: 0.1877\n",
      "  Spline 2 grad norm: 0.2474\n",
      "  Weights grad norm: 0.3988\n",
      "Epoch 155: Errors = 178, LR = 0.009000\n",
      "  Mean product: 1.6206, Mean displacement: -1.6206, Weights mean: 1.1300, Weights std: 0.9021\n",
      "  Spline 0 grad norm: 0.0207\n",
      "  Spline 1 grad norm: 0.2144\n",
      "  Spline 2 grad norm: 0.2991\n",
      "  Weights grad norm: 0.4723\n",
      "Epoch 160: Errors = 159, LR = 0.009000\n",
      "  Mean product: 1.6276, Mean displacement: -1.6276, Weights mean: 1.0976, Weights std: 0.9949\n",
      "  Spline 0 grad norm: 0.0118\n",
      "  Spline 1 grad norm: 0.2410\n",
      "  Spline 2 grad norm: 0.3522\n",
      "  Weights grad norm: 0.5441\n",
      "Epoch 165: Errors = 137, LR = 0.009000\n",
      "  Mean product: 1.6106, Mean displacement: -1.6106, Weights mean: 1.0651, Weights std: 1.0938\n",
      "  Spline 0 grad norm: 0.0033\n",
      "  Spline 1 grad norm: 0.2595\n",
      "  Spline 2 grad norm: 0.4022\n",
      "  Weights grad norm: 0.6043\n",
      "Epoch 170: Errors = 107, LR = 0.009000\n",
      "  Mean product: 1.5727, Mean displacement: -1.5727, Weights mean: 1.0336, Weights std: 1.1960\n",
      "  Spline 0 grad norm: 0.0232\n",
      "  Spline 1 grad norm: 0.2642\n",
      "  Spline 2 grad norm: 0.4454\n",
      "  Weights grad norm: 0.6141\n",
      "Epoch 175: Errors = 69, LR = 0.009000\n",
      "  Mean product: 1.5205, Mean displacement: -1.5205, Weights mean: 1.0037, Weights std: 1.2979\n",
      "  Spline 0 grad norm: 0.0417\n",
      "  Spline 1 grad norm: 0.2437\n",
      "  Spline 2 grad norm: 0.4747\n",
      "  Weights grad norm: 0.5944\n",
      "Epoch 180: Errors = 52, LR = 0.009000\n",
      "  Mean product: 1.4625, Mean displacement: -1.4625, Weights mean: 0.9753, Weights std: 1.3967\n",
      "  Spline 0 grad norm: 0.0604\n",
      "  Spline 1 grad norm: 0.2101\n",
      "  Spline 2 grad norm: 0.4741\n",
      "  Weights grad norm: 0.5137\n",
      "Epoch 185: Errors = 33, LR = 0.009000\n",
      "  Mean product: 1.4209, Mean displacement: -1.4209, Weights mean: 0.9497, Weights std: 1.4884\n",
      "  Spline 0 grad norm: 0.0630\n",
      "  Spline 1 grad norm: 0.1384\n",
      "  Spline 2 grad norm: 0.3208\n",
      "  Weights grad norm: 0.3141\n",
      "Epoch 190: Errors = 27, LR = 0.009000\n",
      "  Mean product: 1.4123, Mean displacement: -1.4123, Weights mean: 0.9291, Weights std: 1.5687\n",
      "  Spline 0 grad norm: 0.0724\n",
      "  Spline 1 grad norm: 0.1219\n",
      "  Spline 2 grad norm: 0.3175\n",
      "  Weights grad norm: 0.3119\n",
      "Epoch 195: Errors = 22, LR = 0.009000\n",
      "  Mean product: 1.4522, Mean displacement: -1.4522, Weights mean: 0.9136, Weights std: 1.6406\n",
      "  Spline 0 grad norm: 0.0912\n",
      "  Spline 1 grad norm: 0.1167\n",
      "  Spline 2 grad norm: 0.3325\n",
      "  Weights grad norm: 0.3339\n",
      "Epoch 200: Errors = 19, LR = 0.009000\n",
      "  Mean product: 1.5581, Mean displacement: -1.5581, Weights mean: 0.9039, Weights std: 1.7090\n",
      "  Spline 0 grad norm: 0.1013\n",
      "  Spline 1 grad norm: 0.1008\n",
      "  Spline 2 grad norm: 0.4609\n",
      "  Weights grad norm: 0.4504\n",
      "Epoch 205: Errors = 13, LR = 0.009000\n",
      "  Mean product: 1.7425, Mean displacement: -1.7425, Weights mean: 0.9016, Weights std: 1.7787\n",
      "  Spline 0 grad norm: 0.1280\n",
      "  Spline 1 grad norm: 0.1154\n",
      "  Spline 2 grad norm: 0.2472\n",
      "  Weights grad norm: 0.3381\n",
      "Epoch 210: Errors = 11, LR = 0.009000\n",
      "  Mean product: 2.0376, Mean displacement: -2.0376, Weights mean: 0.9029, Weights std: 1.8443\n",
      "  Spline 0 grad norm: 0.1552\n",
      "  Spline 1 grad norm: 0.1072\n",
      "  Spline 2 grad norm: 0.5081\n",
      "  Weights grad norm: 0.2618\n",
      "Epoch 215: Errors = 8, LR = 0.009000\n",
      "  Mean product: 2.4365, Mean displacement: -2.4365, Weights mean: 0.9039, Weights std: 1.9015\n",
      "  Spline 0 grad norm: 0.1877\n",
      "  Spline 1 grad norm: 0.1304\n",
      "  Spline 2 grad norm: 0.2264\n",
      "  Weights grad norm: 0.2855\n",
      "Epoch 220: Errors = 6, LR = 0.009000\n",
      "  Mean product: 2.8368, Mean displacement: -2.8368, Weights mean: 0.9067, Weights std: 1.9589\n",
      "  Spline 0 grad norm: 0.1279\n",
      "  Spline 1 grad norm: 0.1810\n",
      "  Spline 2 grad norm: 0.9439\n",
      "  Weights grad norm: 0.4832\n",
      "Epoch 225: Errors = 5, LR = 0.009000\n",
      "  Mean product: 3.0780, Mean displacement: -3.0780, Weights mean: 0.9087, Weights std: 2.0206\n",
      "  Spline 0 grad norm: 0.1359\n",
      "  Spline 1 grad norm: 0.1204\n",
      "  Spline 2 grad norm: 0.2008\n",
      "  Weights grad norm: 0.2772\n",
      "Epoch 230: Errors = 6, LR = 0.009000\n",
      "  Mean product: 3.3282, Mean displacement: -3.3282, Weights mean: 0.9094, Weights std: 2.0793\n",
      "  Spline 0 grad norm: 0.1572\n",
      "  Spline 1 grad norm: 0.1352\n",
      "  Spline 2 grad norm: 0.7435\n",
      "  Weights grad norm: 0.2744\n",
      "Epoch 235: Errors = 5, LR = 0.008100\n",
      "  Mean product: 3.6651, Mean displacement: -3.6651, Weights mean: 0.9075, Weights std: 2.1354\n",
      "  Spline 0 grad norm: 0.1244\n",
      "  Spline 1 grad norm: 0.1624\n",
      "  Spline 2 grad norm: 0.2442\n",
      "  Weights grad norm: 0.2528\n",
      "Epoch 240: Errors = 5, LR = 0.008100\n",
      "  Mean product: 3.9432, Mean displacement: -3.9432, Weights mean: 0.9018, Weights std: 2.1843\n",
      "  Spline 0 grad norm: 0.1027\n",
      "  Spline 1 grad norm: 0.1789\n",
      "  Spline 2 grad norm: 0.2944\n",
      "  Weights grad norm: 0.2107\n",
      "Epoch 245: Errors = 3, LR = 0.008100\n",
      "  Mean product: 4.1715, Mean displacement: -4.1715, Weights mean: 0.8937, Weights std: 2.2319\n",
      "  Spline 0 grad norm: 0.1020\n",
      "  Spline 1 grad norm: 0.1529\n",
      "  Spline 2 grad norm: 0.1609\n",
      "  Weights grad norm: 0.1094\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OptimizedPyTorchGradientSMPA(device=&#x27;cpu&#x27;, epochs=250, learning_rate=0.01,\n",
       "                             spline_type=&#x27;pchip&#x27;, track_history=True,\n",
       "                             verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OptimizedPyTorchGradientSMPA</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>OptimizedPyTorchGradientSMPA(device=&#x27;cpu&#x27;, epochs=250, learning_rate=0.01,\n",
       "                             spline_type=&#x27;pchip&#x27;, track_history=True,\n",
       "                             verbose=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "OptimizedPyTorchGradientSMPA(device='cpu', epochs=250, learning_rate=0.01,\n",
       "                             spline_type='pchip', track_history=True,\n",
       "                             verbose=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize and fit model\n",
    "model = OptimizedPyTorchGradientSMPA(\n",
    "    learning_rate=0.01, epochs=250, random_state=7, verbose=True,\n",
    "    spline_type='pchip', track_history=True, lambda_reg=0.0001, weight_reg=0.001\n",
    ")\n",
    "model.fit(X_train_reordered, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9962\n",
      "Test Accuracy: 0.9950\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAGGCAYAAABmGOKbAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAbl9JREFUeJzt3XlcFfX+x/HXYVUEVFRADHHLfc2VVNzBNU27rqWWV8vUSstKy12zrKwss9um9ivLq7nnhnvuueCuqbmUimuAoiLL/P6Yy9ETqKDAOcD7+XjMg3Nm5sx8Bj9BH76bxTAMAxERERERERHJcE72DkBEREREREQkp1LRLSIiIiIiIpJJVHSLiIiIiIiIZBIV3SIiIiIiIiKZREW3iIiIiIiISCZR0S0iIiIiIiKSSVR0i4iIiIiIiGQSFd0iIiIiIiIimURFt4iIiIiIiEgmUdEtIiIiIiIikklUdIuISK4yY8YMLBbLXbetW7faO8R7WrduHR07dsTf3x83Nzd8fX1p164d8+bNs3doIiIikgoXewcgIiJiD2PHjqVkyZIp9pcpU8YO0aTNqFGjGDt2LI8++ijPP/88QUFBXL58maVLl9KpUyd++OEHunfvbu8wRURE5A4qukVEJFdq1aoVtWrVStdnEhISSEpKws3NLcWx2NhY8uXL98DxGIbBzZs3yZs3b6rH586dy9ixY3nqqaeYNWsWrq6u1mNDhw5lxYoVxMfHP/D9HcHDfg9FREQckbqXi4iIpOLkyZNYLBY++OADPv74Y0qXLo27uzsHDx5k9OjRWCwWDh48SPfu3SlYsCANGjQAzMJ83Lhx1vNLlCjB8OHDiYuLs7l+iRIlaNu2LStWrKBWrVrkzZuX//znP3eNZ8SIEfj4+PDtt9/aFNzJwsLCaNu2rfX9hQsX6NOnD35+fuTJk4dq1aoxc+bMuz7jl19+aY25du3a/Pbbb9bzPvjgAywWC6dOnUpx32HDhuHm5sbff/9t3bdt2zZatmxJ/vz58fDwoFGjRmzatMnmc/f6HiYlJTF69GgCAgLw8PCgSZMmHDx4kBIlStC7d2+b60RFRfHKK68QGBiIu7s7ZcqU4b333iMpKSndz5ns8OHDdO7cmSJFipA3b17KlSvHW2+9ZXPOmTNneO655/Dz88Pd3Z1KlSrx7bffpriWiIiIWrpFRCRXio6O5tKlSzb7LBYLhQoVstk3ffp0bt68Sb9+/XB3d8fHx8d67F//+hePPvoo77zzDoZhAPDvf/+bmTNn8tRTT/Hqq6+ybds2Jk6cyKFDh5g/f77NtY8cOUK3bt14/vnn6du3L+XKlUs11qNHj3L48GGee+45vLy87vtsN27coHHjxhw7doyBAwdSsmRJ5syZQ+/evYmKiuLll1+2OX/WrFlcvXqV559/HovFwqRJk+jYsSN//PEHrq6udO7cmddff53//ve/DB061Oaz//3vfwkNDaVgwYIArFmzhlatWlGzZk1GjRqFk5MT06dPp2nTpvz666/UqVPH5vOpfQ+HDRvGpEmTaNeuHWFhYezZs4ewsDBu3rxp89nr16/TqFEjzpw5w/PPP0/x4sXZvHkzw4YN49y5c3z88cfpek6AvXv30rBhQ1xdXenXrx8lSpTg+PHjLF68mAkTJgBw/vx56tWrh8ViYeDAgRQpUoRly5bRp08fYmJieOWVV+77byQiIrmIISIikotMnz7dAFLd3N3dreedOHHCAAxvb2/jwoULNtcYNWqUARjdunWz2R8REWEAxr///W+b/a+99poBGGvWrLHuCwoKMgBj+fLl94154cKFBmB89NFHaXrGjz/+2ACM77//3rrv1q1bRnBwsOHp6WnExMTYPGOhQoWMK1eupLjf4sWLrfuCg4ONmjVr2txn+/btBmB89913hmEYRlJSkvHoo48aYWFhRlJSkvW869evGyVLljRatGhh3Xe372FkZKTh4uJidOjQwWb/6NGjDcDo1auXdd+4ceOMfPnyGb///rvNuW+++abh7OxsnD59Ot3PGRISYnh5eRmnTp2yueadz9OnTx+jaNGixqVLl2zO6dq1q5E/f37j+vXrhoiISDJ1LxcRkVxp6tSphIeH22zLli1LcV6nTp0oUqRIqtd44YUXbN4vXboUgCFDhtjsf/XVVwH45ZdfbPaXLFmSsLCw+8YaExMDkKZW7uQ4/P396datm3Wfq6srL730EteuXWP9+vU253fp0sXaUg3QsGFDAP744w+bc3bu3Mnx48et+2bPno27uzvt27cHICIigqNHj9K9e3cuX77MpUuXuHTpErGxsTRr1owNGzbYdPuGlN/D1atXk5CQwIsvvmizf9CgQSmec86cOTRs2JCCBQta73Xp0iWaN29OYmIiGzZsSNdzXrx4kQ0bNvDcc89RvHhxm89aLBbAHHv/888/065dOwzDsLlvWFgY0dHR7Nq1K0WsIiKSe6l7uYiI5Ep16tRJ00Rqqc1wfrdjp06dwsnJKcUM6P7+/hQoUCDFmOh7XftO3t7eAFy9ejVN5586dYpHH30UJyfbv61XqFDBevxO/ywwkwvTO8dp/+tf/2LIkCHMnj2b4cOHYxgGc+bMoVWrVtb4jh49CkCvXr3uGlt0dLRN4Zva9xBSziLv4+Nj87nk++3du/eufxS5cOFCup4zufiuXLnyXeO/ePEiUVFRfPnll3z55Zdpuq+IiORuKrpFRETu4W6zid/rWHKr6MNc+07ly5cHYN++fWk6P72cnZ1T3W/8b4w1QEBAAA0bNuS///0vw4cPZ+vWrZw+fZr33nvPek5yK/b7779P9erVU72mp6enzfu0fg9Sk5SURIsWLXj99ddTPV62bFmb92l5zrTcE+Dpp5++6x8XqlatmubriYhIzqeiW0REJIMEBQWRlJTE0aNHra3KYE68FRUVRVBQ0ANdt2zZspQrV46FCxfyySefpChcU4tj7969JCUl2bR2Hz582Hr8QXTp0oUXX3yRI0eOMHv2bDw8PGjXrp31eOnSpQGzZb558+YPdI/k2I4dO2bTCn758mWblvfk+127du2B7/VPpUqVAmD//v13PadIkSJ4eXmRmJiYYfcVEZGcTWO6RUREMkjr1q0BUsyaPXnyZADatGnzwNceM2YMly9f5t///jcJCQkpjq9cuZIlS5ZY44iMjGT27NnW4wkJCXz66ad4enrSqFGjB4qhU6dOODs78+OPPzJnzhzatm1rs652zZo1KV26NB988AHXrl1L8fmLFy/e9x7NmjXDxcWFadOm2ez/7LPPUpzbuXNntmzZwooVK1Ici4qKSvX7dC9FihQhJCSEb7/9ltOnT9scS24Nd3Z2plOnTvz888+pFudpeUYREcld1NItIiK50rJly6wtv3d6/PHHrS2e6VWtWjV69erFl19+SVRUFI0aNWL79u3MnDmTDh060KRJkweOt0uXLuzbt48JEyawe/duunXrRlBQEJcvX2b58uWsXr2aWbNmAdCvXz/+85//0Lt3b3bu3EmJEiWYO3cumzZt4uOPP07zhGz/5OvrS5MmTZg8eTJXr16lS5cuNsednJz4+uuvadWqFZUqVeLZZ5+lWLFinDlzhrVr1+Lt7c3ixYvveQ8/Pz9efvllPvzwQ5544glatmzJnj17WLZsGYULF7bpuj906FAWLVpE27Zt6d27NzVr1iQ2NpZ9+/Yxd+5cTp48SeHChdP1jFOmTKFBgwY89thj9OvXj5IlS3Ly5El++eUXIiIiAHj33XdZu3YtdevWpW/fvlSsWJErV66wa9cuVq1axZUrV9J1TxERydlUdIuISK40cuTIVPdPnz79gYtugK+//ppSpUoxY8YM5s+fj7+/P8OGDWPUqFEPfM1k48ePp2nTpkyZMoVp06Zx5coVChYsSL169Vi4cCFPPPEEYI6TXrduHW+++SYzZ84kJiaGcuXKMX36dHr37v1QMXTp0oVVq1bh5eVlbdm/U+PGjdmyZQvjxo3js88+49q1a/j7+1O3bl2ef/75NN3jvffew8PDg6+++opVq1YRHBzMypUradCgAXny5LGe5+Hhwfr163nnnXeYM2cO3333Hd7e3pQtW5YxY8aQP3/+dD9ftWrV2Lp1KyNGjGDatGncvHmToKAgOnfubD3Hz8+P7du3M3bsWObNm8fnn39OoUKFqFSpks0YdxEREQCLkZ7ZQ0RERETsICoqioIFCzJ+/Hjeeuste4cjIiKSZhrTLSIiIg7lxo0bKfYlj5Nv3Lhx1gYjIiLykNS9XERERBzK7NmzmTFjBq1bt8bT05ONGzfy448/EhoaSv369e0dnoiISLqo6BYRERGHUrVqVVxcXJg0aRIxMTHWydXGjx9v79BERETSTWO6RURERERERDKJxnSLiIiIiIiIZBIV3SIiIiIiIiKZRGO6gaSkJM6ePYuXlxcWi8Xe4YiIiIiIiIiDMwyDq1evEhAQgJPT3duzVXQDZ8+eJTAw0N5hiIiIiIiISDbz559/8sgjj9z1uIpuwMvLCzC/Wd7e3naOJnXx8fGsXLmS0NBQXF1d7R2OiJVyUxyVclMclXJTHJVyUxyVo+ZmTEwMgYGB1nryblR0g7VLube3t0MX3R4eHnh7eztUookoN8VRKTfFUSk3xVEpN8VROXpu3m+IsiZSExEREREREckkKrpFREREREREMomKbhEREREREZFMYtcx3dOmTWPatGmcPHkSgEqVKjFy5EhatWoFQOPGjVm/fr3NZ55//nm++OIL6/vTp0/Tv39/1q5di6enJ7169WLixIm4uGi4uoiIiIiI5GyJiYnEx8fbO4xMFR8fj4uLCzdv3iQxMTHL7uvq6oqzs/NDX8eulekjjzzCu+++y6OPPophGMycOZP27duze/duKlWqBEDfvn0ZO3as9TMeHh7W14mJibRp0wZ/f382b97MuXPn6NmzJ66urrzzzjtZ/jwiIiIiIiJZwTAMIiMjiYqKsncomc4wDPz9/fnzzz/vO2lZRitQoAD+/v4PdV+7Ft3t2rWzeT9hwgSmTZvG1q1brUW3h4cH/v7+qX5+5cqVHDx4kFWrVuHn50f16tUZN24cb7zxBqNHj8bNzS3Tn0FERERERCSrJRfcvr6+eHh4ZHkxmpWSkpK4du0anp6eODllzQhpwzC4fv06Fy5cAKBo0aIPfC2H6YOdmJjInDlziI2NJTg42Lr/hx9+4Pvvv8ff35927doxYsQIa2v3li1bqFKlCn5+ftbzw8LC6N+/PwcOHKBGjRpZ/hwiIiIiIiKZKTEx0VpwFypUyN7hZLqkpCRu3bpFnjx5sqzoBsibNy8AFy5cwNfX94G7mtu96N63bx/BwcHcvHkTT09P5s+fT8WKFQHo3r07QUFBBAQEsHfvXt544w2OHDnCvHnzAPOvO3cW3ID1fWRk5F3vGRcXR1xcnPV9TEwMYI4VcNTxEMlxOWp8knspN8VRKTfFUSk3xVEpN7OPuLg4DMMgT548JCUl2TucTGcYhvVrVj9vnjx5MAyDGzdu4O7ubnMsrf+t2L3oLleuHBEREURHRzN37lx69erF+vXrqVixIv369bOeV6VKFYoWLUqzZs04fvw4pUuXfuB7Tpw4kTFjxqTYv3LlSpsx444oPDzc3iGIpEq5KY5KuSmOSrkpjkq56fhcXFzw9/cnNjY2V/2R5OrVq1l+z1u3bnHjxg3Wr19PQkKCzbHr16+n6RoWI/nPBg6iefPmlC5dmv/85z8pjsXGxuLp6cny5csJCwtj5MiRLFq0iIiICOs5J06coFSpUuzateuu3ctTa+kODAzk0qVLeHt7Z/gzZYTr1+NZty6cFi1a4Orqau9wRKzi4+MJD1duiuNRboqjUm6Ko1JuZh83b97kzz//pESJEuTJk8fe4WQ6wzC4evUqXl5eWT52/ebNm5w8eZLAwMAU3+uYmBgKFy5MdHT0PetIu7d0/1NSUpJNQXyn5OI6eRB7cHAwEyZMsPaxB/Mvc97e3tYu6qlxd3dP0TUAzCnhHfUHTI8ezuzZ05RWrdxp3NiZkBB45BF7RyVymyP/9yO5m3JTHJVyUxyVctPxJSYmYrFYcHJyytIxzvaS3KU8+ZmzkpOTExaLJdX/LtL634ld/4WGDRvGhg0bOHnyJPv27WPYsGGsW7eOHj16cPz4ccaNG8fOnTs5efIkixYtomfPnoSEhFC1alUAQkNDqVixIs888wx79uxhxYoVvP322wwYMCDVojq7SkqCzZst/PWXF1995UyPHhAYCGFhsGGDvaMTERERERFJm969e2OxWFJsLVu2tHdomcauLd0XLlygZ8+enDt3jvz581O1alVWrFhBixYt+PPPP1m1ahUff/wxsbGxBAYG0qlTJ95++23r552dnVmyZAn9+/cnODiYfPny0atXL5t1vXMCJyc4eDCBKVN2ceNGLTZtcmbnTli50twaNoS2bc3zALy84PHHoVKl2/tEREREREQcQcuWLZk+fbrNvrs1msbHx6eYNfzWrVsPtDz0g37uYdm16P7mm2/ueiwwMJD169ff9xpBQUEsXbo0I8NySIUKQd26kbRunYSrqzMnTsCkSfDtt/Drr+b2TwULmgX56NGg1dNERERERMQRuLu74+/vn+oxi8XC559/zrJly1i9ejVDhw7FMAzmzZvHoEGDmDhxIqdOnSIpKYnTp08zaNAgVq9ejZOTEy1btuTTTz+1rmg1evRoFixYwMCBA5kwYYL1c3PnzmXMmDEcO3YMDw8PatSowcKFC8mXL1+mPK/DjemWtClZEqZNg7ffhs8/hz//vH3s3DnYsgX+/hsWLYK1a2HZMqhf337xioiIiIhI5jAMSONE2hnOwwMyem6z0aNH8+677/Lxxx/j4uLCN998w4kTJ5g3bx7z5s3D2dmZpKQk2rdvj6enp3Vm8QEDBtClSxfWrVtnvdaxY8f4+eefrZ87d+4c3bp1Y9KkSTz55JNcvXqVX3/9lcycX1xFdzZXrBhMmJByf3w87N4Nr78O69eb478XL4YmTbI+RhERERERyTzXr4Onp33ufe0apLeBeMmSJXj+I+Dhw4czfPhwALp3786zzz5rc/zWrVvMnDnT2oodHh7Ovn37OHHiBIGBgQB89913VKpUid9++43atWtbP/fdd99RpEgRAHbt2kVCQgIdO3YkKCgIMJenzkwa8ZtDubpCnTqwdCmEhkJsLLRuDTNmwOXL9o5ORERERERyqyZNmhAREWGzvfDCC9bjtWrVSvGZwMBAa+EMcOjQIQIDA60FN0DFihUpUKAAhw4dsu4LCgqy+Vy1atVo1qwZVapU4V//+hdfffUVf//9d0Y/og21dOdwHh6wcCF07my2dCf/wahyZQgJMcd8h4RAQIB94xQRERERkQfj4WG2ONvr3umVL18+ypQpc8/jKe/zADdK5VrOzs6Eh4ezefNmVq5cyaeffspbb73Ftm3bKFmy5APd437U0p0L5MkDc+fCsGFQvry5b/9+cyx4t25mF/UyZeCddyA62r6xioiIiIhI+lgsZhdve2wZPZ47rSpUqMCff/7Jn3dMbnXw4EGioqKoWLHiPT9rsVioX78+Y8aMYffu3bi5uTF//vxMi1VFdy7h5mYW1YcOwfnz8PPP8PLL5qzmFgscPw5vvQVBQTBihLqgi4iIiIhI5oiLiyMyMtJmu3TpUrqu0bx5c6pUqUKPHj3YtWsX27dvp2fPnjRq1CjV7unJtm3bxjvvvMOOHTs4ffo08+bN4+LFi1SoUOFhH+uuVHTnQr6+0LEjfPwx7NplznL+f/8HFSuaLd3jx5vF+Llz9o5URERERERymuXLl1O0aFGbrUGDBum6hsViYeHChRQsWJCQkBCaN29OqVKlmD179j0/5+3tzYYNG2jdujVly5bl7bff5sMPP6RVq1YP80j3pDHdQv788PTT0L07LFgAQ4fCH3/Ak0/CunVm93QREREREZGHNWPGDGbMmHHX46kt3TVq1CgGDx6cYn/x4sVZuHDhXa81evRoRo8ebbOvQoUKLF++PM3xZgS1dIuVk5PZAr5iBRQsCNu2Qd++5rp/IiIiIiIikn4quiWFMmVgzhxwdobvv4f337d3RCIiIiIiItmTim5JVbNmMGWK+frNN83lxkRERERERCR9VHTLXb34IvTvb3Yv797dXGZMRERERERE0k5Ft9zTJ59AkyZw7Rq0awcXL9o7IhERERERkexDRbfck6urOb67dGk4eRKeegpu3bJ3VCIiIiIikpSUZO8QcryM+B5ryTC5r0KFYNEiqFcPNmyAXr3Mdb1dlD0iIiIiIlnOzc0NJycnzp49S5EiRXBzc8Nisdg7rEyTlJTErVu3uHnzJk5OWdNubBgGt27d4uLFizg5OeHm5vbA11LZJGlSsSLMng1PPAE//WS2dv/4IzxE7omIiIiIyANwcnKiZMmSnDt3jrNnz9o7nExnGAY3btwgb968Wf7HBQ8PD4oXL/5Qxb6KbkmzVq1g3jyzi/m8eeaa3nPnQp489//slSuwcaPZUn7lCjz7LDRsmPkxi4iIiIjkRG5ubhQvXpyEhAQSExPtHU6mio+PZ8OGDYSEhODq6ppl93V2dsbFxeWhC30V3ZIu7dqZXc07dIBffoHHHjOL8ZAQCAyELVvMwnr7doiLMz9jGBAZaXud6dPNz7z9NjRvDjm4N4yIiIiISKawWCy4urpmaSFqD87OziQkJJAnT55s+awquiXdwsJg2TKzAD90yNwmT77/58qXNwvtxERzTPiGDRAaCnXqmMV327YqvkVEREREJGdR0S0PpHFjOH4cVq0yi+cNG+DsWbOADgmB+vWhYMHb5wcEgK/v7fejR8MHH8CXX5qt4k88AdWqwdix5msREREREZGcQEW3PDBfX+je3dzS65FH4OOPYfhw+Ogj+Owz2LMH2reHPn3M9cHz5cvwkEVERERERLKU1ukWu/L1hYkT4dQpeP11s3v5N99AzZqwe7e9oxMREREREXk4KrrFIfj4wHvvwZo1Zlf0I0egbl14/nn44w97RyciIiIiIvJgVHSLQ2ncGPbuNWdHj483x3yXLQu9esHJk3YOTkREREREJJ1UdIvDKVQI5s83J2cLCzNnO//uO3OitZ9+snd0IiIiIiIiaaeiWxxWw4awfLk5u3lwMMTEQLdu8NxzcO2avaMTERERERG5PxXd4vBq1zZbvUeMMCdamz4dKlWCL76AmzftHZ2IiIiIiMjdqeiWbMHFxVzDe+1ac7mx06ehf38oXdpc7/vwYTAMe0cpIiIiIiJiS0W3ZCuNGpkzm0+ZYhbfZ8/C0KFQoQL4+cFTT8GCBZCUZO9IRUREREREVHRLNuThAYMGwbFj5uzmjRpBnjxw8SL8/DM8+eTtSdcSE+0drYiIiIiI5GZ2LbqnTZtG1apV8fb2xtvbm+DgYJYtW2Y9fvPmTQYMGEChQoXw9PSkU6dOnD9/3uYap0+fpk2bNnh4eODr68vQoUNJSEjI6kcRO3B3h759Yd06iIqCjRvh9dfBywv27zcnXXvkEejaFT7/HA4dsnfEIiIiIiKS29i16H7kkUd499132blzJzt27KBp06a0b9+eAwcOADB48GAWL17MnDlzWL9+PWfPnqVjx47WzycmJtKmTRtu3brF5s2bmTlzJjNmzGDkyJH2eiSxE3d3qF8f3nsPTp0yx3/7+EBkJMyeDQMGQMWK0Ly5WaRr/LeIiIiIiGQFuxbd7dq1o3Xr1jz66KOULVuWCRMm4OnpydatW4mOjuabb75h8uTJNG3alJo1azJ9+nQ2b97M1q1bAVi5ciUHDx7k+++/p3r16rRq1Ypx48YxdepUbt26Zc9HEzsqWNCc6fzMGbPAHjsWmjUzJ2NbvRqaNDGXI/vyS03AJiIiIiIimcvF3gEkS0xMZM6cOcTGxhIcHMzOnTuJj4+nefPm1nPKly9P8eLF2bJlC/Xq1WPLli1UqVIFPz8/6zlhYWH079+fAwcOUKNGjVTvFRcXR1xcnPV9TEwMAPHx8cTHx2fSEz6c5LgcNT5H5OwMjz9ubm++abaAf/ihE9OnO7Fpk4VNm8zzihQxaNAgeUuialXzs5I2yk1xVMpNcVTKTXFUyk1xVI6am2mNx+5F9759+wgODubmzZt4enoyf/58KlasSEREBG5ubhQoUMDmfD8/PyIjIwGIjIy0KbiTjycfu5uJEycyZsyYFPtXrlyJh4fHQz5R5goPD7d3CNlay5ZQp4474eFB7N9fmCNHfLh40Zn58y3Mnw/gjItLIi4ut5u/AwOvUrHiZSpVukyFCpfx8nKs/9gdhXJTHJVyUxyVclMclXJTHJWj5eb169fTdJ7di+5y5coRERFBdHQ0c+fOpVevXqxfvz5T7zls2DCGDBlifR8TE0NgYCChoaF4e3tn6r0fVHx8POHh4bRo0QJXV1d7h5PtPf20+fXWrSR27jT49VcLGzda2LzZQkyMM3fOxXf0aEGOHi3IwoVlAKhc2aBhwyRq1jTIk+f+93J3h1q1DIoVy4QHcQDKTXFUyk1xVMpNcVTKTXFUjpqbyT2m78fuRbebmxtlypjFTM2aNfntt9/45JNP6NKlC7du3SIqKsqmtfv8+fP4+/sD4O/vz/bt222ulzy7efI5qXF3d8fd3T3FfldXV4f6R0xNdogxO3F1hZAQcwNzibG//rq9zvetW7BjB/z6K2zYYM6Avn+/hf3709//vHRpcyy5r+/tfUWKmPsee8yMJTtTboqjUm6Ko1JuiqNSboqjcrTcTGssdi+6/ykpKYm4uDhq1qyJq6srq1evplOnTgAcOXKE06dPExwcDEBwcDATJkzgwoUL+P6vkgkPD8fb25uKFSva7Rkk+3J2hqAg233lykGPHubrCxfMpck2bDCXJUsuzu/lyhXYtw+OHze31Hh4mGPPQ0LMIrxuXcib9+GeRURERERE7M+uRfewYcNo1aoVxYsX5+rVq8yaNYt169axYsUK8ufPT58+fRgyZAg+Pj54e3szaNAggoODqVevHgChoaFUrFiRZ555hkmTJhEZGcnbb7/NgAEDUm3JFnlYvr7QsaO5pUd0NGzeDFu2QPLQD8OAP/4wW9EvX4ZVq8wNwM0Nnn0WPvwQ8uXL2GcQEREREZGsY9ei+8KFC/Ts2ZNz586RP39+qlatyooVK2jRogUAH330EU5OTnTq1Im4uDjCwsL4/PPPrZ93dnZmyZIl9O/fn+DgYPLly0evXr0YO3asvR5JJFX580OrVub2T0lJZrf1DRvMbf16OHcO/vMfc8mzn36C6tWzOmIREREREckIdi26v/nmm3sez5MnD1OnTmXq1Kl3PScoKIilS5dmdGgiWcbJCSpVMrf+/c0W8DVroGdPOHLE7Gr+9tvwxBNQubKWMxMRERERyU6c7B2AiNiyWKBZM9izxyy0b92CkSPN1u5Chcx9y5ebxbmIiIiIiDg2Fd0iDqpwYViwAKZPN9cX9/Iyx4YvXmx2U69dG+bPT9tkbiIiIiIiYh8qukUcmMUCvXvDsmXmLOg7dsCQIeZs5zt3mhO6FSkCHTqYk64dOGDviEVERERE5E4qukWyCRcXqFnTLK5PnYK33jInaLtyBRYuhNdeM8d8t2ljzpIuIiIiIiL2p6JbJBsqXBjGj4eLF2HrVnj/fWjd2pyUbelSc83vJk3gk09g925ITLR3xCIiIiIiuZNdZy8XkYfj6mrObl63rtnSfewYvPsuzJxpLje2bp15nre3ucZ4suLFzW7qrVubXdhFRERERCRzqKVbJAcpUwa+/hqOH4d33jEnXPPygpgYsyBP3tasgbZt4bHH4OefNRmbiIiIiEhmUdEtkgMVLw7Dhpldzf/+21x+bONGc9uwAYYOhXz5ICICnnrKLMAvXLB31CIiIiIiOY+KbpEcztkZqlaF+vXNrWFDmDTJnIzt7bchTx5zdvSqVWHlSntHKyIiIiKSs2hMt0guVagQjBsHXbpA167mcmNhYVCpkjkhG4CPDzRoACEhEBxsdlUXEREREZG0U9EtkstVrgy//QavvgrTpqVc63v9epgwwWwxf+wxs6U8JMQsxgsVsk/MIiIiIiLZhYpuESFvXvj8cxg4EM6du73/1ClzDPiGDXDihFmc//YbTJ5sHq9cGRo0cKJgQX/CwszZ1EVERERE5DYV3SJiVbGiud3puefMr3/+Cb/+ersIP3QI9u+H/fudgbr8/LPBW29Bt24qvkVEREREkqnoFpE0CQyE7t3NDczZzjduhDVrEpk5M5Hff3ejVy8YPhyKFTPPsVjMtcCHDVMhLiIiIiK5k4puEXkgvr7QsSO0a5dE/frhnDjRkk8+cebMGThz5vZ527bBL7/ArFlQurT94hURERERsQctGSYiD83DI4GhQ5M4cQJWrIDFi83tiy+gQAHYvh1q1IDvvoOkJHtHKyIiIiKSdVR0i0iG8fCA0FBo29bcnn8e9uwxZzq/ehV69YJq1eCnnyAx0d7RioiIiIhkPhXdIpKpiheHtWth/Hhzne/9+83J1ipUgDfegCVL4O+/7R2liIiIiEjmUNEtIpnOxQXeestcgmzsWPDxgaNHYdIkaNfOXO87NNRcE9ww7B2tiIiIiEjGUdEtIlmmYEEYMQJOnjTHd//731C2rFloh4dD48bQsCEsWAAxMXYOVkREREQkA6joFpEs5+UFzzwDX30FR47AH3/Aiy+Cuzts2gRPPmkW6LVqwZAhMH8+XLpk76hFRERERNJPS4aJiN2VLAlTp5pd0CdPNovsP/6AnTvN7aOPzPMqVjTXC08WFARjxoC/v33iFhERERG5HxXdIuIwAgLggw/M7a+/4NdfYcMGczt48PZ2pwULYOZMaNnSLiGLiIiIiNyTim4RcUiPPGLOct6tm/n+0iXYvBmio833iYlmq/i+fdCqFQweDK+/rlZvEREREXEsKrpFJFsoXBieeMJ2X9euMHQofPaZ2QX9o4/MidlCQqBjR7P122KxT7wiIiIiIqCJ1EQkG8uTBz79FBYtgurVzQL799/h66+hdWuoWRN+/hmSkuwdqYiIiIjkViq6RSTba9cOdu+Gy5dhyRJ46SXw9DT3PfWUWZCfOGHvKEVEREQkN1LRLSI5RsGC0KYNfPKJuRb4yJFQoIA57jskxGwFFxERERHJSiq6RSRHKlTIXE7s4EGoUMGcDb1Ro5Szn4uIiIiIZCa7Ft0TJ06kdu3aeHl54evrS4cOHThy5IjNOY0bN8ZisdhsL7zwgs05p0+fpk2bNnh4eODr68vQoUNJSEjIykcREQdVtCisWwdVq0JkpFl4f/gh7NgB+jEhIiIiIpnNrrOXr1+/ngEDBlC7dm0SEhIYPnw4oaGhHDx4kHz58lnP69u3L2PHjrW+9/DwsL5OTEykTZs2+Pv7s3nzZs6dO0fPnj1xdXXlnXfeydLnERHH5OsLa9dCaCjs3AmvvWbu9/SEYsVS/4yzszkWPCTE3IKCbh9zdzePi4iIiIjcj12L7uXLl9u8nzFjBr6+vuzcuZOQkBDrfg8PD/zvsvjuypUrOXjwIKtWrcLPz4/q1aszbtw43njjDUaPHo2bm1umPoOIZA8+Pmbh/dVXZsv3r79CVBT8o3ONjYMHYdaslPu9vKB/fxgyBPz8MitiEREREckJHGpMd3R0NAA+Pj42+3/44QcKFy5M5cqVGTZsGNevX7ce27JlC1WqVMHvjv/zDQsLIyYmhgMHDmRN4CKSLXh5mYXyokXmTOf79sGGDalvy5bBqFHQpAnkzWt7natXYdIkKFECXn4ZNm+GW7fs8kgiIiIi4uDs2tJ9p6SkJF555RXq169P5cqVrfu7d+9OUFAQAQEB7N27lzfeeIMjR44wb948ACIjI20KbsD6PjIyMtV7xcXFERcXZ30fExMDQHx8PPHx8Rn6XBklOS5HjU9yr+ycm+XK3ft4s2bw1lvm2O+bN819hgEbNliYONGJ7dudmDIFpkyBPHkM6tY16N49id69DSyWzI9f7i0756bkbMpNcVTKTXFUjpqbaY3HYhiGkcmxpEn//v1ZtmwZGzdu5JFHHrnreWvWrKFZs2YcO3aM0qVL069fP06dOsWKFSus51y/fp18+fKxdOlSWrVqleIao0ePZsyYMSn2z5o1y2a8uIjI3RgG7N1bhBUrgjhwoDDR0e7WY7Vrn2PQoAi8vdX8LSIiIpJTXb9+ne7duxMdHY23t/ddz3OIonvgwIEsXLiQDRs2ULJkyXueGxsbi6enJ8uXLycsLIyRI0eyaNEiIiIirOecOHGCUqVKsWvXLmrUqJHiGqm1dAcGBnLp0qV7frPsKT4+nvDwcFq0aIGrq6u9wxGxUm6aBfiRI7BggRPjxztx65aFgACD6dMTadLE7j9icy3lpjgq5aY4KuWmOCpHzc2YmBgKFy5836I73d3Lb9y4gWEY1hbhU6dOMX/+fCpWrEhoaGi6rmUYBoMGDWL+/PmsW7fuvgU3YC2uixYtCkBwcDATJkzgwoUL+Pr6AhAeHo63tzcVK1ZM9Rru7u64u7un2O/q6upQ/4ipyQ4xSu6U23OzShVze+IJ6NoVDh+20LKlC2++aa4Xnou/NXaX23NTHJdyUxyVclMclaPlZlpjSfdEau3bt+e7774DICoqirp16/Lhhx/Svn17pk2blq5rDRgwgO+//55Zs2bh5eVFZGQkkZGR3LhxA4Djx48zbtw4du7cycmTJ1m0aBE9e/YkJCSEqlWrAhAaGkrFihV55pln2LNnDytWrODtt99mwIABqRbWIiKZqVo1cw3wvn3NFvCJE6FhQ/jjD3tHJiIiIiL2kO6ie9euXTRs2BCAuXPn4ufnx6lTp/juu++YMmVKuq41bdo0oqOjady4MUWLFrVus2fPBsDNzY1Vq1YRGhpK+fLlefXVV+nUqROLFy+2XsPZ2ZklS5bg7OxMcHAwTz/9ND179rRZ11tEJCvlywdffglz5kCBArBtm7nm9+TJEBtr7+hEREREJCulu3v59evX8fLyAsw1sjt27IiTkxP16tXj1KlT6brW/YaTBwYGsn79+vteJygoiKVLl6br3iIime2pp6B2bejRAzZtgldfNVu+Bw82u6E7/e/Pnp6eEBiIZjwXERERyYHSXXSXKVOGBQsW8OSTT7JixQoGDx4MwIULFxx2EjIREXsJCoJ162DGDHj3XTh+3FyG7K23bM8rVgxCQqB+fbN1PDU+PtCiBbg4zGKPIiIiInI/6f5ft5EjR9K9e3cGDx5Ms2bNCA4OBsxW79RmChcRye1cXODf/4bevWH2bLOb+Z0dg6Kj4cwZ+PFHc7uXUqVg2DDo2RPc3DI1bBERERHJAOkuup966ikaNGjAuXPnqFatmnV/s2bNePLJJzM0OBGRnMTFxexq3qOH7f7r181x3xs2wG+/wa27LO+9e7c5IVvfvjB6NJQtm/p5+fJBvXpmy3nt2pAnT4Y+hoiIiIikQ7qK7vj4ePLmzUtERESKVu06depkaGAiIrmFhwc0aWJu9xIba07Q9v77Zsv4mTN3P3fJEvOrq6t5/WR168J//gMlSjx02CIiIiKSBukqul1dXSlevDiJiYmZFY+IiNxFvnzmJGz9+0N4uNlCnprz52HjRrPl/Px5s/t6spUrzZnUv/wSOnfOkrBFREREcrV0dy9/6623GD58OP/3f/+Hj49PZsQkIiL3kCcPtGt373NeeslcJ/zPP+HmTXNfTAwMGgRbt0KXLvDzz/Doo+YxFxdo3RrUaUlEREQkY6W76P7ss884duwYAQEBBAUFkS9fPpvju3btyrDgRETkwVksULy47b4NG2DMGHjnHfjvf22PjRljzo7+1lvmeHAtYSYiIiLy8NJddHfo0CETwhARkazg6grjx0PLljBvHiSPFoqMNFu+w8PNrUoVaNoUGjY0N19f+8YtIiIikl2lu+geNWpUZsQhIiJZqEEDc7vTyZPw3nvw7bewb5+5ffKJeax8ebP1u0EDKFTo4e6dNy/UqgVeXg93HREREZHsIN1Fd7KdO3dy6NAhACpVqqQ1ukVEsrkSJWDaNLOb+dq1Zlf0DRtg/344fNjcvvwyY+7l5AQ1apiFfHIxX7hwxlxbRERExJGku+i+cOECXbt2Zd26dRQoUACAqKgomjRpwk8//USRIkUyOkYREclCvr7mRGtdupjvL1+GTZvMAnzbttsTsz2oy5fhxAnYudPcPvrI3F+p0u0ivGFDKFbs4e4jIiIi4gjSXXQPGjSIq1evcuDAASpUqADAwYMH6dWrFy+99BI//vhjhgcpIiL2U6gQPPGEuWWUM2fg119vt6YfOHB7mzbNPKdUqdtFeEiI+V6Tu4mIiEh2k+6ie/ny5axatcpacANUrFiRqVOnEhoamqHBiYhIzlSsGHTtam4Aly7dXlt8wwbYvRv++MPcZswwz6lTB95+G9q2fbjiOy4O9uyB2NiHfgwri8Vc//x/HcBERERErNJddCclJeHq6ppiv6urK0lJSRkSlIiI5C6FC0OHDuYG5priW7bcLsK3bYPt283W9qpVoVs3cyb2e0lMdOLQodIcOeKEszNcuWIW9tu2mYV3RvPygoEDYfBg0EgrERERSZbuortp06a8/PLL/PjjjwQEBABw5swZBg8eTLNmzTI8QBERyX28vSEszNwAzp83x35PnQp795rb/TkDlVM9UqRIxi6DFhMDf/4JEyfCxx9Dmzbg7m4ec3MzZ2sPCYGKFc1J5ERERCT3SHfR/dlnn/HEE09QokQJAgMDAfjzzz+pXLky33//fYYHKCIi4ucH774Lr78OX3wB/1s8456SkpI4c+YMxYoVw8nJiTx5oG5ds/h99NGMHR+elASLF5troO/YAXPn2h6fPt386uMDnTubz1GyZMbdX0RERBxXuovuwMBAdu3axapVqzh8+DAAFSpUoHnz5hkenIiIyJ18fGD48LSdGx+fyNKlu2jd2h9X18xtXnZygvbtze7va9bYtsRHRcHmzeZ25Yr5R4OvvoIePaB3b8iTxzzPzc2cwT35vYiIiOQM6Sq64+PjyZs3LxEREbRo0YIWLVpkVlwiIiLZjsUCzZqZ2z/Fx5sztk+aBCtWwHffmdud3N3N1viGDeF/I7gAKFjQXMv8fx3MREREJBtJV9Ht6upK8eLFSUxMzKx4REREciRXV2ja1Nx++w3ee8+cpT1ZdLS5hnny5HGpKVEC6tWDfPlSP55cnDdoYC71JiIiIvaX7u7lb731FsOHD+f//u//8PHxyYyYREREcrTatVOO+zYMOHrULLg3b4arV28fO3UKdu2CkyfN7V4++MD8Wq7c3YvzAgWgfn1zfHtw8N3PExERkYf3QBOpHTt2jICAAIKCgsj3j9/Uu3btyrDgREREcguLBcqWNbd//zvl8atXzWXUdu+Gu3U4O3XK7MJ+6BAcOXLv+61Zk/r+4GBz3HybNhk72ZyIiEhule6iu0PyIqoiIiKSZby8IDTU3O7nwgXYs+fuxfnp02Zxvn69udTZnbZsgXbtoFo16NsXPDzM/S4u8NhjUKGClj0TERFJj3QV3QkJCVgsFp577jkeeeSRzIpJREREHoKvL9xvrtN+/cyvly9DQoL5OjYWvvzSXA99zx4YODDl53x8zIne7pzULX9+s7v644+br69eNbvIb9oEf/99+zw/P7MV39//4Z5PREQkO0lX0e3i4sL7779Pz549MyseERERyUL/nHAteT30qVNh27bb+69dMyeAu3IFFi5M/VpOTub64ydOmGuXp2bCBLPwfv11zcYuIiK5Q7q7lzdt2pT169dTokSJTAhHRERE7M3HB0aMSLk/Pt6c0G3jRnO29WR//ml2Vz9+3NwASpUyW8SLFzffGwasWgVbt8Jnn5lF/Z1rkjdtaray37lUmoiISE6Q7qK7VatWvPnmm+zbt4+aNWummEjtiSeeyLDgRERExHG4uprriNetm/rxs2fhwAGoWBGKFUt5fOxYWLsWxo83v964cfvYL79A1aowYwa0bZsp4YuIiNhFuovuF198EYDJkyenOGaxWLSGt4iISC4VEHDvlmqL5fZa5ZGREBdn7r940Rxjvnu3OYlb9+6pF+3pERhoLolWuTI4Oz/ctURERB5GuovupLsN0hIRERFJozsnUwsKMmdNHz4cJk+GWbMy7j4FCpgzsbv87/94XF2hQwfo3Rvc3TPuPiIiIneT7qJbREREJKO5u8OHH5pdy5ctM8eAP6ikJLOb+6ZNEBVlLo12p+XLYdw4eO01c1I3T8+HCl1EROSe0lx0t27dmh9//JH8+fMD8O677/LCCy9QoEABAC5fvkzDhg05ePBgmm8+ceJE5s2bx+HDh8mbNy+PP/447733HuXKlbOec/PmTV599VV++ukn4uLiCAsL4/PPP8fPz896zunTp+nfvz9r167F09OTXr16MXHiRFxc9DcFERGR7KRJE3PLCAkJEBEBv/9+e99ff8GUKXDmDAwebM6iXru22RX9scfMlnAw/wjQqNHtdcpFREQeVJqr0hUrVhCXPPgKeOedd+jcubO16E5ISODIkSPpuvn69esZMGAAtWvXJiEhgeHDhxMaGsrBgwetE7QNHjyYX375hTlz5pA/f34GDhxIx44d2bRpEwCJiYm0adMGf39/Nm/ezLlz5+jZsyeurq6888476YpHREREcg4XF6hVy9zu9PLLMHMmTJpkzra+ebO5/dOjj8JPP5nFuIiIyINKc9Ft/KOf1z/fP4jly5fbvJ8xYwa+vr7s3LmTkJAQoqOj+eabb5g1axZNmzYFYPr06VSoUIGtW7dSr149Vq5cycGDB1m1ahV+fn5Ur16dcePG8cYbbzB69Gjc3NweOk4RERHJOdzdzYnb+vY11xTfsMHsgn5ni/ixY3D0KNSrZ65d/sor5jrkIiIi6eVQvz6i/7fop4+PDwA7d+4kPj6e5s2bW88pX748xYsXZ8uWLQBs2bKFKlWq2HQ3DwsLIyYmhgMHDmRh9CIiIpKdWCzmeuK9e8P06eYY8OTt0CF48klzbfJXXzVnXF+//uHGmouISO6U5pZui8WCxWJJsS+jJCUl8corr1C/fn0qV64MQGRkJG5ubtYu7Mn8/PyIjIy0nnNnwZ18PPlYauLi4my6ysfExAAQHx9PfHx8hjxPRkuOy1Hjk9xLuSmOSrkpD8PLy+xa/vXXTrz6qhPr11to3Bjq10/itdeSaNLEeODx3spNcVTKTXFUjpqbaY0nXd3Le/fujfv/1te4efMmL7zwgnXs9Z1F7IMYMGAA+/fvZ+PGjQ91nbSYOHEiY8aMSbF/5cqVeDj4jCnh4eH2DkEkVcpNcVTKTXkYxYrBlCl5mT//UVatKs6mTc5s2uSEi0sSZcr8TaVKl6lY8TLly18hX76EdF1buSmOSrkpjsrRcvP69etpOi/NRXevXr1s3j/99NMpzunZs2daL2dj4MCBLFmyhA0bNvDII49Y9/v7+3Pr1i2ioqJsWrvPnz+P//8W+PT392f79u021zt//rz1WGqGDRvGkCFDrO9jYmIIDAwkNDQUb2/vB3qGzBYfH094eDgtWrTANXlqVREHoNwUR6XclIzUuzecPZvExx/Df//rxNmzThw+XIjDhwvx88/g5GRQtSp07pzEK68kca8FVJSb4qiUm+KoHDU3k3tM30+ai+7p06c/cDB3YxgGgwYNYv78+axbt46SJUvaHK9Zsyaurq6sXr2aTp06AXDkyBFOnz5NcHAwAMHBwUyYMIELFy7g6+sLmH8B8fb2pmLFiqne193d3dpifydXV1eH+kdMTXaIUXIn5aY4KuWmZJSgIPjoI5g8+fYEbL/+an49dsxCRARERDjzyy/O/PCDef69KDfFUSk3xVE5Wm6mNRa7LmQ9YMAAZs2axcKFC/Hy8rKOwc6fPz958+Ylf/789OnThyFDhuDj44O3tzeDBg0iODiYevXqARAaGkrFihV55plnmDRpEpGRkbz99tsMGDAg1cJaRERE5GEkT8CWPAkbwNmzsGiRue73pk1QrRp8+SX861/m+SIiknvZdfbyadOmER0dTePGjSlatKh1mz17tvWcjz76iLZt29KpUydCQkLw9/dn3rx51uPOzs4sWbIEZ2dngoODefrpp+nZsydjx461xyOJiIhILhQQAC+8ABERULcuREdDly7QoAEsXapZz0VEcjO7tnSnZa3vPHnyMHXqVKZOnXrXc4KCgli6dGlGhiYiIiKSbqVKmV3Ox4yBDz6AzZuhTRt47DHo3h1CQuB/i7SIiEguYdeiW0RERCSncXWF8eNhwAD48EP44gvYtcvcAPLlc6FatVr4+5ut4iIikrOlqXv5Y489xt9//w3A2LFj0zw1uoiIiEhuVbSo2dp98qRZfLdrBwUKQGyshc2bi1GvniutW5sTsSUm2jtaERHJLGkqug8dOkRsbCwAY8aM4dq1a5kalIiIiEhOUbgwDBliTrR2+TJs3RpPo0Z/4uRksGwZNGoEPj5mN/T33oOLF+0dsYiIZKQ0dS+vXr06zz77LA0aNMAwDD744AM8PT1TPXfkyJEZGqCIiIhITuHkZI7vHjx4F9Om+TN5siuzZ0NMjDnh2tKl5qzna9bcf8kxERHJHtJUdM+YMYNRo0axZMkSLBYLy5Ytw8Ul5UctFouKbhEREZE0KFMGvvrKHPO9Z485AduUKfDHH9CwoVl4lylj7yhFRORhpanoLleuHD/99BMATk5OrF69Gl9f30wNTERERCQ3cHY2W78fewyeegqaN4fDh82ZzlevhgoV7B2hiIg8jHSv052UlKSCW0RERCQTFCsG69aZy4qdOwe1apnjwc+etXdkIiLyoNJddAMcP36cQYMG0bx5c5o3b85LL73E8ePHMzo2ERERkVzHzw/WroUGDeD6dfjoIyhZ0lyCTHPZiohkP+kuulesWEHFihXZvn07VatWpWrVqmzbto1KlSoRHh6eGTGKiIiI5CqFC5tLiS1fDvXrw61b8PnnEBoK0dH2jk5ERNIjTWO67/Tmm28yePBg3n333RT733jjDVq0aJFhwYmIiIjkVhYLhIWZhfaqVdC5M2zZYo75XrHCXGZMREQcX7pbug8dOkSfPn1S7H/uuec4ePBghgQlIiIiIiaLBVq0MGczL1QIduyAJk1g/34wDHtHJyIi95PuortIkSJERESk2B8REaEJ1kREREQySY0asH69OeZ7716oUgV8faFjR5g1SwW4iIijSnf38r59+9KvXz/++OMPHn/8cQA2bdrEe++9x5AhQzI8QBERERExVapkjvV++WWzAL90CebPN7effzbX/Va3cxERx5LuonvEiBF4eXnx4YcfMmzYMAACAgIYPXo0L730UoYHKCIiIiK3lS0Ly5aZk6vt3AlLlsD778O8ebB9O/zwg7nGt4iIOIZ0dy+3WCwMHjyYv/76i+joaKKjo/nrr794+eWXsVgsmRGjiIiIiPyDmxsEB8OECbB5M5QpA3/9ZY73Hj0aEhLsHaGIiMADrtOdzMvLCy8vr4yKRUREREQeQK1asGsX9OoFSUkwZgw0bgynTtk7MhEReaiiW0REREQcg5cXzJhhdi/38oJNm6B6dVi71t6RiYjkbiq6RURERHKQ7t0hIgLq1IGoKHjpJc1sLiJiTyq6RURERHKYUqVgxQrIk8dcz3vnTntHJCKSe6Wr6I6Pj6dZs2YcPXo0s+IRERERkQxQoAA8+aT5esYMe0YiIpK7pavodnV1Ze/evZkVi4iIiIhkoN69za+zZkFcnF1DERHJtdLdvfzpp5/mm2++yYxYRERERCQDNWsGxYrB33/DokX2jkZEJHdySe8HEhIS+Pbbb1m1ahU1a9YkX758NscnT56cYcGJiIiIyINzdoaePWHiRLOL+b/+Ze+IRERyn3QX3fv37+exxx4D4Pfff7c5ZrFYMiYqEREREckQvXubRffy5XDuHBQtau+IRERyl3QX3Wu12KOIiIhItlG2LDz+OGzeDN9/D0OH2jsiEZHc5YGXDDt27BgrVqzgxo0bABhaAFJERETEISVPqPbRRzB+PGzYADdv2jUkEZFcI91F9+XLl2nWrBlly5aldevWnDt3DoA+ffrw6quvZniAIiIiIvJwOneG/PnN7uUjRkCjRlC4MEybBmo3ERHJXOkuugcPHoyrqyunT5/Gw8PDur9Lly4sX748Q4MTERERkYeXPz9ERMBnn5kFuL8/xMbCiy9Cx45w+bK9IxQRybnSXXSvXLmS9957j0ceecRm/6OPPsqpU6cyLDARERERyTglSsCAATB7Npw5Y3Y1d3WFBQugWjXYutXeEYqI5EzpLrpjY2NtWriTXblyBXd39wwJSkREREQyj5MTvPKKWWiXLWsW4a1bw7Fj9o5MRCTnSXfR3bBhQ7777jvre4vFQlJSEpMmTaJJkybputaGDRto164dAQEBWCwWFixYYHO8d+/eWCwWm61ly5Y251y5coUePXrg7e1NgQIF6NOnD9euXUvvY4mIiIjkOo89Bjt3Qp068Pff8MQTEB1t76hERHKWdC8ZNmnSJJo1a8aOHTu4desWr7/+OgcOHODKlSts2rQpXdeKjY2lWrVqPPfcc3Ts2DHVc1q2bMn06dOt7//Zmt6jRw/OnTtHeHg48fHxPPvss/Tr149Zs2al99FEREREch1PT7OLee3acOgQdOsGixeDs7O9IxMRyRnSXXRXrlyZ33//nc8++wwvLy+uXbtGx44dGTBgAEWLFk3XtVq1akWrVq3ueY67uzv+/v6pHjt06BDLly/nt99+o1atWgB8+umntG7dmg8++ICAgIB0xSMiIiKSGxUtCgsXQsOGsGwZvPEGfPCBvaMSEckZ0l10A+TPn5+33noro2NJ1bp16/D19aVgwYI0bdqU8ePHU6hQIQC2bNlCgQIFrAU3QPPmzXFycmLbtm08+eSTqV4zLi6OuLg46/uYmBgA4uPjiY+Pz8SneXDJcTlqfJJ7KTfFUSk3xVE5am5WrQpff22hRw8XPvwQQkISaNVK64nlJo6amyKOmptpjeeBiu6///6bb775hkOHDgFQsWJFnn32WXx8fB7kcnfVsmVLOnbsSMmSJTl+/DjDhw+nVatWbNmyBWdnZyIjI/H19bX5jIuLCz4+PkRGRt71uhMnTmTMmDEp9q9cuTLVSeIcSXh4uL1DEEmVclMclXJTHJUj5ma+fNC2bWWWLClN794JfPLJGry9Het/ciXzOWJuioDj5eb169fTdF66i+7kyc/y589vbWGeMmUKY8eOZfHixYSEhKT3knfVtWtX6+sqVapQtWpVSpcuzbp162jWrNkDX3fYsGEMGTLE+j4mJobAwEBCQ0Px9vZ+qJgzS3x8POHh4bRo0QJXV1d7hyNipdwUR6XcFEfl6LnZpAnUrWtw+HAeFi5syaxZiVgs9o5KsoKj56bkXo6am8k9pu8n3UX3gAED6NKlC9OmTcP5fzNsJCYm8uKLLzJgwAD27duX3kumWalSpShcuDDHjh2jWbNm+Pv7c+HCBZtzEhISuHLlyl3HgYM5Tjy15c1cXV0d6h8xNdkhRsmdlJviqJSb4qgcNTddXeH776FePfj5ZyfmznWie3d7RyVZyVFzU8TRcjOtsaR7ybBjx47x6quvWgtuAGdnZ4YMGcKxTF7c8a+//uLy5cvWCduCg4OJiopi586d1nPWrFlDUlISdevWzdRYRERERHKqmjVhxAjz9YABcPq0feMREcnO0l10P/bYY9ax3Hc6dOgQ1apVS9e1rl27RkREBBEREQCcOHGCiIgITp8+zbVr1xg6dChbt27l5MmTrF69mvbt21OmTBnCwsIAqFChAi1btqRv375s376dTZs2MXDgQLp27aqZy0VEREQewvDh5vrdUVHQoQPExto7IhGR7ClN3cv37t1rff3SSy/x8ssvc+zYMerVqwfA1q1bmTp1Ku+++266br5jxw6aNGlifZ88zrpXr15MmzaNvXv3MnPmTKKioggICCA0NJRx48bZdA3/4YcfGDhwIM2aNcPJyYlOnToxZcqUdMUhIiIiIrZcXOC//zXX7969G3r3htmzwSndTTYiIrlbmoru6tWrY7FYMIzby0a8/vrrKc7r3r07Xbp0SfPNGzdubHPNf1qxYsV9r+Hj48OsWbPSfE8RERERSZugIJg3D5o2hblzYexYGD3a3lGJiGQvaSq6T5w4kdlxiIiIiIgDatAAvvgC+vSBMWPMQvzZZ+0dlYhI9pGmojsoKCiz4xARERERB/Xcc3DgAEyebL7euBGmTDHX9RYRkXtL95JhAGfPnmXjxo1cuHCBpKQkm2MvvfRShgQmIiIiIo5j0iTw8IAJE+Dbb83C+6efoEYNe0cmIuLY0l10z5gxg+effx43NzcKFSqExWKxHrNYLCq6RURERHIgZ2cYNw6aNYOnn4bff4eGDSEiAsqUsXd0IiKOK93zT44YMYKRI0cSHR3NyZMnOXHihHX7448/MiNGEREREXEQjRvDnj1Qv765jFjPnpCQYO+oREQcV7qL7uvXr9O1a1ectF6EiIiISK5UqBDMmgXe3rBli9n1XEREUpfuyrlPnz7MmTMnM2IRERERkWyieHH49FPz9ahR5lreIiKSUrrHdE+cOJG2bduyfPlyqlSpgqurq83xyZMnZ1hwIiIiIuK4nnkGFiyA+fPN1zt2QJ489o5KRMSxPFDRvWLFCsqVKweQYiI1EREREckdLBb4z39g0yZzSbGPPoJhw+wdlYiIY0l30f3hhx/y7bff0rt370wIR0RERESykyJF4MMPzZbuSZOgf38oUMDeUYmIOI50j+l2d3enfv36mRGLiIiIiGRD3bpBxYoQFQUaaSgiYivdRffLL7/Mp8mzZoiIiIhIrufsDGPHmq8/+gguXbJvPCIijiTd3cu3b9/OmjVrWLJkCZUqVUoxkdq8efMyLDgRERERyR46doQaNcxZzCdN0jJiIiLJ0l10FyhQgI4dO2ZGLCIiIiKSTVksMH48tGkDn30GgwdD0aL2jkpExP7SXXRPnz49M+IQERERkWyuVSt4/HHYvBneegu+/dbeEYmI2F+6x3SLiIiIiKTGYoGJE82v06fDF1/YOyIREftLd0t3yZIl77ke9x9//PFQAYmIiIhI9hUSAhMmwPDhMGgQlCsHTZrYOyoREftJd9H9yiuv2LyPj49n9+7dLF++nKFDh2ZUXCIiIiKSTb35JuzfD7NmwVNPwfbtULq0vaMSEbGPdBfdL7/8cqr7p06dyo4dOx46IBERERHJ3iwW+PprOHbMLLifeMKc1dzNzd6RiYhkvQwb092qVSt+/vnnjLqciIiIiGRjefPCggXg5wcHD5pFuIhIbpRhRffcuXPx8fHJqMuJiIiISDZXtCiMHGm+Hj8ebtywbzwiIvaQ7u7lNWrUsJlIzTAMIiMjuXjxIp9//nmGBiciIiIi2du//w2TJsGpU/D55/Dqq/aOSEQka6W76O7QoYPNeycnJ4oUKULjxo0pX758RsUlIiIiIjmAmxuMGgXPPQfvvgv9+oGXl72jEhHJOukuukeNGpUZcYiIiIhIDvXMM+b63UePwiefwNtv2zsiEZGsk2FjukVEREREUuPiAmPGmK8/+AAuX7ZvPCIiWSnNRbeTkxPOzs733Fxc0t1wLiIiIiK5QJcuULkyREdD3brw22/2jkhEJGukuUqeP3/+XY9t2bKFKVOmkJSUlCFBiYiIiEjO4uQE//d/0L49HD8Ojz8OEybAa6+Zx0REcqo0F93t27dPse/IkSO8+eabLF68mB49ejB27NgMDU5EREREco7q1SEiAp5/HubMgTfeMMd5f/WVvSMTEck8D/R3xbNnz9K3b1+qVKlCQkICERERzJw5k6CgoIyOT0RERERykIIFYfZs+PJLsFjg66/h11/tHZWISOZJV9EdHR3NG2+8QZkyZThw4ACrV69m8eLFVK5c+YFuvmHDBtq1a0dAQAAWi4UFCxbYHDcMg5EjR1K0aFHy5s1L8+bNOXr0qM05V65coUePHnh7e1OgQAH69OnDtWvXHigeEREREcl8Fgv07Wuu4Q0waBAkJto3JhGRzJLmonvSpEmUKlWKJUuW8OOPP7J582YaNmz4UDePjY2lWrVqTJ069a73nDJlCl988QXbtm0jX758hIWFcfPmTes5PXr04MCBA4SHh7NkyRI2bNhAv379HiouEREREcl877xjtnzv2QP/+Y+9oxERyRxpHtP95ptvkjdvXsqUKcPMmTOZOXNmqufNmzcvzTdv1aoVrVq1SvWYYRh8/PHHvP3229bx5N999x1+fn4sWLCArl27cujQIZYvX85vv/1GrVq1APj0009p3bo1H3zwAQEBAWmORURERESyVuHCMG4cDBxort3dubO5T0QkJ0lzS3fPnj3p3LkzPj4+5M+f/65bRjlx4gSRkZE0b97cui9//vzUrVuXLVu2AOas6QUKFLAW3ADNmzfHycmJbdu2ZVgsIiIiIpI5nn8eqlWDv/82C28RkZwmzS3dM2bMyMQwUoqMjATAz8/PZr+fn5/1WGRkJL6+vjbHXVxc8PHxsZ6Tmri4OOLi4qzvY2JiAIiPjyc+Pj5D4s9oyXE5anySeyk3xVEpN8VRKTdT+ugjC02buvDllwYtWiTyxBOGvUPKlZSb4qgcNTfTGk+ai+6cZOLEiYwZMybF/pUrV+Lh4WGHiNIuPDzc3iGIpEq5KY5KuSmOSrlpq3XrKixdWoqnn4Z3391IiRIx9g4p11JuiqNytNy8fv16ms5z2KLb398fgPPnz1O0aFHr/vPnz1O9enXrORcuXLD5XEJCAleuXLF+PjXDhg1jyJAh1vcxMTEEBgYSGhqKt7d3Bj5FxomPjyc8PJwWLVrg6upq73BErJSb4qiUm+KolJupa9EC2rZNYu1aFz76qDGbNydQpIi9o8pdlJviqBw1N5N7TN+PwxbdJUuWxN/fn9WrV1uL7JiYGLZt20b//v0BCA4OJioqip07d1KzZk0A1qxZQ1JSEnXr1r3rtd3d3XF3d0+x39XV1aH+EVOTHWKU3Em5KY5KuSmOSrlpy9UV5s6FOnXg+HELXbq4sno1uLnZO7LcR7kpjsrRcjOtsaRrne6Mdu3aNSIiIoiIiADMydMiIiI4ffo0FouFV155hfHjx7No0SL27dtHz549CQgIoEOHDgBUqFCBli1b0rdvX7Zv386mTZsYOHAgXbt21czlIiIiItmMjw8sXgze3rBxI3z8sb0jEhF5eHYtunfs2EGNGjWoUaMGAEOGDKFGjRqMHDkSgNdff51BgwbRr18/ateuzbVr11i+fDl58uSxXuOHH36gfPnyNGvWjNatW9OgQQO+/PJLuzyPiIiIiDycChVuF9sffwx3zH0rIpIt2bV7eePGjTGMu89OabFYGDt2LGPHjr3rOT4+PsyaNSszwhMRERERO+jRA0aMgDNn4Icf4Lnn7B2RiMiDs2tLt4iIiIjIP7m5wSuvmK/ffx+SkuwajojIQ1HRLSIiIiIOp18/c2z34cPwyy/2jkZE5MGp6BYRERERh+PtDf9bsIZJk+wbi4jIw1DRLSIiIiIO6aWXzKXENm6EzZvtHY2IyINR0S0iIiIiDikgAJ55xnz94Yf2jUVE5EGp6BYRERERhzV4sPl10SK4cMG+sYiIPAgV3SIiIiLisCpXhlq1ICEBtEqsiGRHKrpFRERExKH17m1+nTHDnlGIiDwYFd0iIiIi4tC6dTPX7t6zByIi7B2NiEj6qOgWEREREYfm4wPt25uvp0+3bywiIumloltEREREHF5yF/MffoBbt+waiohIuqjoFhERERGHFxoKRYvC5cvwyy/2jkZEJO1UdIuIiIiIw3Nxub1mtyZUE5HsREW3iIiIiGQLvXqZX3/5BQ4etG8sIiJppaJbRERERLKFihWhTRtITDRbvePj7R2RiMj9qegWERERkWzjyy/N2cx37YJx4+wdjYjI/anoFhEREZFsIyAApk0zX7/zDmzbZt94RETuR0W3iIiIiGQrnTtDt25mN/OePSE21t4RiYjcnYpuEREREcl2pk6FYsXg99+hXj04cMDeEYmIpE5Ft4iIiIhkOwULwpw54OcH+/dDrVrwxRdgGPaOTETElopuEREREcmWgoNhzx5o2RJu3oT+/c3u5prVXEQciYpuEREREcm2/PzMdbsnTwYXF/j+e+jSBW7dsndkIiImFd0iIiIikq05OcHgwTB/Pri5mV87djRbv0VE7E1Ft4iIiIjkCG3bwuLFkDev2fr9xBPqai4i9qeiW0RERERyjNBQWLYM8uWD8HBzLW8REXtS0S0iIiIiOUqjRvDVV+brceNgxw77xiMiuZuKbhERERHJcbp2hc6dITERnnkGbtywd0Qiklup6BYRERGRHMdigWnToGhROHwY3nzT3hGJSG6loltEREREciQfH/j2W/P1lCnw9ddgGPaNSURyH4cuukePHo3FYrHZypcvbz1+8+ZNBgwYQKFChfD09KRTp06cP3/ejhGLiIiIiCNp2RIGDDBf9+0L3btDdLR9YxKR3MWhi26ASpUqce7cOeu2ceNG67HBgwezePFi5syZw/r16zl79iwdO3a0Y7QiIiIi4mg++cScxdzZGX76CapXhx9+gDNn7B2ZiOQGLvYO4H5cXFzw9/dPsT86OppvvvmGWbNm0bRpUwCmT59OhQoV2Lp1K/Xq1cvqUEVERETEATk7w7Bh0KSJ2dJ94gQ8/bR5rFQp6NLFnOXc2dm+cYpIzuTwLd1Hjx4lICCAUqVK0aNHD06fPg3Azp07iY+Pp3nz5tZzy5cvT/HixdmyZYu9whURERERB1WvHuzebU6qVrMmODnBH3/AxInwwQf2jk5EciqHbumuW7cuM2bMoFy5cpw7d44xY8bQsGFD9u/fT2RkJG5ubhQoUMDmM35+fkRGRt7zunFxccTFxVnfx8TEABAfH098fHyGP0dGSI7LUeOT3Eu5KY5KuSmOSrlpXx4eMHasucXEwNdfO/Hmm86MGGHQvHkCVavaO0L7UW6Ko3LU3ExrPBbDyD5zOEZFRREUFMTkyZPJmzcvzz77rE3xDFCnTh2aNGnCe++9d9frjB49mjFjxqTYP2vWLDw8PDI8bhERERFxTIYBEyfWYfv2ogQFRfPBBxtwdU2yd1gikg1cv36d7t27Ex0djbe3913Pc+iW7n8qUKAAZcuW5dixY7Ro0YJbt24RFRVl09p9/vz5VMeA32nYsGEMGTLE+j4mJobAwEBCQ0Pv+c2yp/j4eMLDw2nRogWurq72DkfESrkpjkq5KY5Kuel4ateGGjUMTp3Kz9atrZk4MXcW3cpNcVSOmpvJPabvJ1sV3deuXeP48eM888wz1KxZE1dXV1avXk2nTp0AOHLkCKdPnyY4OPie13F3d8fd3T3FfldXV4f6R0xNdohRciflpjgq5aY4KuWm4yhWDL76Cjp0gMmTnfH1debFF8HT096R2YdyUxyVo+VmWmNx6InUXnvtNdavX8/JkyfZvHkzTz75JM7OznTr1o38+fPTp08fhgwZwtq1a9m5cyfPPvsswcHBmrlcRERERNKlfXvo08fsbv7GG1CiBIwfrzW9ReThOXTR/ddff9GtWzfKlStH586dKVSoEFu3bqVIkSIAfPTRR7Rt25ZOnToREhKCv78/8+bNs3PUIiIiIpIdffEFfPMNlCkDly/DiBFQuTJs2GDvyEQkO3Po7uU//fTTPY/nyZOHqVOnMnXq1CyKSERERERyKhcXeO456NkT5swxi+7jx831vd9+23zv4tD/9ywijsihW7pFRERERLKaiwt06wYREdC7NyQlmUuMNW0K167ZOzoRyW5UdIuIiIiIpMLTE6ZPh1mzwMsLfv0VnnnGLMJFRNJKRbeIiIiIyD106wYrVoCbGyxYACNH2jsiEclOVHSLiIiIiNxHcLC5rBjAhAlm67eISFqo6BYRERERSYOePeH1183Xzz0Hy5fbNx4RyR5UdIuIiIiIpNE770DbthAXB61amUX4rVv2jkpEHJmKbhERERGRNHJ2hv/+F1580Xz//vtQvz5s3Ajx8faNTUQck4puEREREZF0yJsXpk6F+fOhYEHYsQMaNoQCBaB5c3N5sXXr4MYNe0cqIo5ARbeIiIiIyAPo0AH27jVnNy9UCK5fh9WrYdQoaNIE8uc3i/H/+z9ISLB3tCJiLyq6RUREREQe0COPmDOZX7gA+/fD559D164QEGB2N9+40ZyArVw5c/bzmzftHbGIZDUV3SIiIiIiD8nJCSpVgv794ccf4a+/4Ngxc+K1woXhjz+gXz+zC3rjxjBiBISHw7Vr9o5cRDKbi70DEBERERHJaSwWKF0ahg2Dl14yW7knT4Y//4T1680NzInZatY01wH39Lz9+Xr1oHVrs5gXkexNRbeIiIiISCbKlw9eeQVefhmOHoUNG+DXX82vJ0/C9u3m9k9VqsBbb8FTT5nFuYhkTyq6RURERESygMUCZcua27//be47fdoswHftuj3ZWmysuSzZvn3m+PCyZWH4cOjeHVxd7Re/iDwYdVgREREREbGT4sWhRw/48EP45BNz+/prOHUKxowxlyT7/Xfo3dssvqdNg4sX7R21iKSHWrpFRERERBxMwYIwciQMHmwW2h9+aHZFf/FFcytfHkJCIDDw9mcKFIDHH4dq1dQdXcSRqOgWEREREXFQXl7w+uswaJDZAv7ll+bSZIcPm1tqvL2hfn2zKG/YEGrVAnf3rI1bRG5T0S0iIiIi4uDy5jUL70GD4PJl2LTJXAM8Kur2OX/9Ze6PiYFly8wNIE8e8Pe/fV7+/GaLeEiI+dXb29wfHw9JSVn2SCK5hopuEREREZFspFAheOIJc/unxETYu9ecGT15lvSLF82u6Xfas8fstm7LlXz5WtGokTONGkH16uDyv2rBxcWcTb1gwYx/HpGcTkW3iIiIiEgO4ewMNWqY28svg2GYy5T9/fftc86cub1kWUSEbet2bKwbS5fC0qUpr22xQNWqZpf15K7rd7agi0jqVHSLiIiIiORQycuU/VPHjubXxMTbRXdcXDz/+c8mDKMhGzc6c+zY7fNjY83W8j17zO2zz8z9ZctCWBiMGmW2wItISiq6RURERERyKWdn25nOy5SJpnXrJF57LeX055GR5jjy5K7re/eay5n9/jvMmwc//ACNGmVh8CLZhIpuERERERG5L39/eOopcwOzy/r69fDGG2bh3aQJDB8Obdrc/kxgIDzyiH3iFXEUTvYOQEREREREsp+CBaFDB9i5E5591hw/PmGCOSN68hYYCKVKQe/e8O23cOyYeZ5IbqKWbhEREREReWCenmZBHRoK774L166Z+5OS4NQpOHHC3GbONPcXLWquI54//8Pd18cH+vWDMmUe7joimU1Ft4iIiIiIPLSuXc3tTjExsGXL7XHg27fDuXMwd27G3PPDD817Dh8OlSplzDVFMpqKbhERERERyRTe3ubs5mFh5vsbN8zCe8cOuHXr4a69aRP88gvMmmVu1aqZS5k1amR2abdY7n+NokXBz+/h4hC5HxXdIiIiIiKSJfLmNYvijJrlfPdueOcd+Pnn28uZffpp+q5RtqxZrCdvQUEZE5tIMhXdIiIiIiKSLdWoAXPmmMuZ/fqr2YX911/h4sX7f9YwzM8lL3v29dfm/uLFoUEDc8x4avLnh+eeM1vTM8qFC2bc27aZvQFS4+VlTkiX2rrr9xIXB7/9Zl4/IcF8trp1wcPjocOWNFLRLSIiIiIi2Zq/P/zrX+aWHn//bXZTTx5zvmMHnD5tdle/l3ffhe7dYdgwqFDh9v7Tp29f6+DBtM3UfumSWfSnxXvvQefO5hj2KlVSP+faNXMcffIfIbZuNQvvO7m6QuXKZs8DMLvily9vtvQ3bAhubrc/v2+fOSleakqUgCFDoGbNtMWfW+WYonvq1Km8//77REZGUq1aNT799FPq1Klj77BERERERMRBFSwIbduaG5gF69at5rjzmzdT/8z27bBiBfzf/5lbcuFqGHf/TFpUqWK2QhcunPrx3bthyRL46SdzS77vP8XFpSySfX3NgtrFxSymz5wxr3enTZvgm2/SF/PmzeYfKFq2hNdeg2LF0vf5+ylc+O7fj+wkRxTds2fPZsiQIXzxxRfUrVuXjz/+mLCwMI4cOYKvr6+9wxMRERERkWzA0xOaNze3e9mxw1yTfMEC2+7gzs5mq29IiPnV3f3+98ybF+rUuXt39jvt2WOOYZ8z5+7d0MEcl57cah0SYnZJT55YzjDg5EnYu/d2cX7rFuzadbu1PykJqlc3P1+nTuoFflKS+fyzZsHy5eaW0caPh7feyvjrZrUcUXRPnjyZvn378uyzzwLwxRdf8Msvv/Dtt9/y5ptv2jk6ERERERHJSWrVgvnzza7hsbG39xcuDPnyZd59q1WD2bNh2jS4ejX1c/LkufeM7BYLlCxpbnfq0sX8ev26WVB7et4/nk6dYPRos7v9okUQH5+mx0izPHky9nr2ku2L7lu3brFz506GDRtm3efk5ETz5s3ZsmVLqp+Ji4sj7o6BDTExMQDEx8cTn9GZkkGS43LU+CT3Um6Ko1JuiqNSboqjUm6mX/785nanrPj2eXmZ2908TAyurum7RvHi8Pnn5pYZ4uMdNzfTGk+2L7ovXbpEYmIifv/4c46fnx+HDx9O9TMTJ05kzJgxKfavXLkSDwefxi88PNzeIYikSrkpjkq5KY5KuSmOSrkpjsrRcvP69etpOi/bF90PYtiwYQwZMsT6PiYmhsDAQEJDQ/H29rZjZHcXHx9PeHg4LVq0wDX5z08iDkC5KY5KuSmOSrkpjkq5KY7KUXMzucf0/WT7ortw4cI4Oztz/vx5m/3nz5/H398/1c+4u7vjnsqsBq6urg71j5ia7BCj5E7KTXFUyk1xVMpNcVTKTXFUjpabaY3FKZPjyHRubm7UrFmT1atXW/clJSWxevVqgoOD7RiZiIiIiIiI5HbZvqUbYMiQIfTq1YtatWpRp04dPv74Y2JjY62zmYuIiIiIiIjYQ44ourt06cLFixcZOXIkkZGRVK9eneXLl6eYXE1EREREREQkK+WIohtg4MCBDBw40N5hiIiIiIiIiFhl+zHdIiIiIiIiIo5KRbeIiIiIiIhIJlHRLSIiIiIiIpJJVHSLiIiIiIiIZJIcM5HawzAMA4CYmBg7R3J38fHxXL9+nZiYGIdaEF5EuSmOSrkpjkq5KY5KuSmOylFzM7l+TK4n70ZFN3D16lUAAgMD7RyJiIiIiIiIZCdXr14lf/78dz1uMe5XlucCSUlJnD17Fi8vLywWi73DSVVMTAyBgYH8+eefeHt72zscESvlpjgq5aY4KuWmOCrlpjgqR81NwzC4evUqAQEBODndfeS2WroBJycnHnnkEXuHkSbe3t4OlWgiyZSb4qiUm+KolJviqJSb4qgcMTfv1cKdTBOpiYiIiIiIiGQSFd0iIiIiIiIimURFdzbh7u7OqFGjcHd3t3coIjaUm+KolJviqJSb4qiUm+KosntuaiI1ERERERERkUyilm4RERERERGRTKKiW0RERERERCSTqOgWERERERERySQqurOJqVOnUqJECfLkyUPdunXZvn27vUOSXGT06NFYLBabrXz58tbjN2/eZMCAARQqVAhPT086derE+fPn7Rix5FQbNmygXbt2BAQEYLFYWLBggc1xwzAYOXIkRYsWJW/evDRv3pyjR4/anHPlyhV69OiBt7c3BQoUoE+fPly7di0Ln0JyovvlZu/evVP8HG3ZsqXNOcpNyQwTJ06kdu3aeHl54evrS4cOHThy5IjNOWn5PX769GnatGmDh4cHvr6+DB06lISEhKx8FMlh0pKbjRs3TvGz84UXXrA5JzvkporubGD27NkMGTKEUaNGsWvXLqpVq0ZYWBgXLlywd2iSi1SqVIlz585Zt40bN1qPDR48mMWLFzNnzhzWr1/P2bNn6dixox2jlZwqNjaWatWqMXXq1FSPT5o0iSlTpvDFF1+wbds28uXLR1hYGDdv3rSe06NHDw4cOEB4eDhLlixhw4YN9OvXL6seQXKo++UmQMuWLW1+jv744482x5WbkhnWr1/PgAED2Lp1K+Hh4cTHxxMaGkpsbKz1nPv9Hk9MTKRNmzbcunWLzZs3M3PmTGbMmMHIkSPt8UiSQ6QlNwH69u1r87Nz0qRJ1mPZJjcNcXh16tQxBgwYYH2fmJhoBAQEGBMnTrRjVJKbjBo1yqhWrVqqx6KiogxXV1djzpw51n2HDh0yAGPLli1ZFKHkRoAxf/586/ukpCTD39/feP/99637oqKiDHd3d+PHH380DMMwDh48aADGb7/9Zj1n2bJlhsViMc6cOZNlsUvO9s/cNAzD6NWrl9G+ffu7fka5KVnlwoULBmCsX7/eMIy0/R5funSp4eTkZERGRlrPmTZtmuHt7W3ExcVl7QNIjvXP3DQMw2jUqJHx8ssv3/Uz2SU31dLt4G7dusXOnTtp3ry5dZ+TkxPNmzdny5YtdoxMcpujR48SEBBAqVKl6NGjB6dPnwZg586dxMfH2+Ro+fLlKV68uHJUstSJEyeIjIy0ycX8+fNTt25day5u2bKFAgUKUKtWLes5zZs3x8nJiW3btmV5zJK7rFu3Dl9fX8qVK0f//v25fPmy9ZhyU7JKdHQ0AD4+PkDafo9v2bKFKlWq4OfnZz0nLCyMmJgYDhw4kIXRS072z9xM9sMPP1C4cGEqV67MsGHDuH79uvVYdslNF3sHIPd26dIlEhMTbRIJwM/Pj8OHD9spKslt6taty4wZMyhXrhznzp1jzJgxNGzYkP379xMZGYmbmxsFChSw+Yyfnx+RkZH2CVhypeR8S+3nZfKxyMhIfH19bY67uLjg4+OjfJVM1bJlSzp27EjJkiU5fvw4w4cPp1WrVmzZsgVnZ2flpmSJpKQkXnnlFerXr0/lypUB0vR7PDIyMtWfrcnHRB5WarkJ0L17d4KCgggICGDv3r288cYbHDlyhHnz5gHZJzdVdIvIfbVq1cr6umrVqtStW5egoCD++9//kjdvXjtGJiKSPXTt2tX6ukqVKlStWpXSpUuzbt06mjVrZsfIJDcZMGAA+/fvt5mXRcQR3C0375zXokqVKhQtWpRmzZpx/PhxSpcundVhPjB1L3dwhQsXxtnZOcUMkufPn8ff399OUUluV6BAAcqWLcuxY8fw9/fn1q1bREVF2ZyjHJWslpxv9/p56e/vn2ISyoSEBK5cuaJ8lSxVqlQpChcuzLFjxwDlpmS+gQMHsmTJEtauXcsjjzxi3Z+W3+P+/v6p/mxNPibyMO6Wm6mpW7cugM3PzuyQmyq6HZybmxs1a9Zk9erV1n1JSUmsXr2a4OBgO0Ymudm1a9c4fvw4RYsWpWbNmri6utrk6JEjRzh9+rRyVLJUyZIl8ff3t8nFmJgYtm3bZs3F4OBgoqKi2Llzp/WcNWvWkJSUZP1FLpIV/vrrLy5fvkzRokUB5aZkHsMwGDhwIPPnz2fNmjWULFnS5nhafo8HBwezb98+mz8MhYeH4+3tTcWKFbPmQSTHuV9upiYiIgLA5mdntshNe8/kJvf3008/Ge7u7saMGTOMgwcPGv369TMKFChgM0ufSGZ69dVXjXXr1hknTpwwNm3aZDRv3twoXLiwceHCBcMwDOOFF14wihcvbqxZs8bYsWOHERwcbAQHB9s5asmJrl69auzevdvYvXu3ARiTJ082du/ebZw6dcowDMN49913jQIFChgLFy409u7da7Rv394oWbKkcePGDes1WrZsadSoUcPYtm2bsXHjRuPRRx81unXrZq9HkhziXrl59epV47XXXjO2bNlinDhxwli1apXx2GOPGY8++qhx8+ZN6zWUm5IZ+vfvb+TPn99Yt26dce7cOet2/fp16zn3+z2ekJBgVK5c2QgNDTUiIiKM5cuXG0WKFDGGDRtmj0eSHOJ+uXns2DFj7Nixxo4dO4wTJ04YCxcuNEqVKmWEhIRYr5FdclNFdzbx6aefGsWLFzfc3NyMOnXqGFu3brV3SJKLdOnSxShatKjh5uZmFCtWzOjSpYtx7Ngx6/EbN24YL774olGwYEHDw8PDePLJJ41z587ZMWLJqdauXWsAKbZevXoZhmEuGzZixAjDz8/PcHd3N5o1a2YcOXLE5hqXL182unXrZnh6ehre3t7Gs88+a1y9etUOTyM5yb1y8/r160ZoaKhRpEgRw9XV1QgKCjL69u2b4o/nyk3JDKnlJWBMnz7dek5afo+fPHnSaNWqlZE3b16jcOHCxquvvmrEx8dn8dNITnK/3Dx9+rQREhJi+Pj4GO7u7kaZMmWMoUOHGtHR0TbXyQ65aTEMw8i6dnURERERERGR3ENjukVEREREREQyiYpuERERERERkUyioltEREREREQkk6joFhEREREREckkKrpFREREREREMomKbhEREREREZFMoqJbREREREREJJOo6BYRERERERHJJCq6RUREJMNZLBYWLFhg7zBERETsTkW3iIhIDtO7d28sFkuKrWXLlvYOTUREJNdxsXcAIiIikvFatmzJ9OnTbfa5u7vbKRoREZHcSy3dIiIiOZC7uzv+/v42W8GCBQGz6/e0adNo1aoVefPmpVSpUsydO9fm8/v27aNp06bkzZuXQoUK0a9fP65du2ZzzrfffkulSpVwd3enaNGiDBw40Ob4pUuXePLJJ/Hw8ODRRx9l0aJFmfvQIiIiDkhFt4iISC40YsQIOnXqxJ49e+jRowddu3bl0KFDAMTGxhIWFkbBggX57bffmDNnDqtWrbIpqqdNm8aAAQPo168f+/btY9GiRZQpU8bmHmPGjKFz587s3buX1q1b06NHD65cuZKlzykiImJvFsMwDHsHISIiIhmnd+/efP/99+TJk8dm//Dhwxk+fDgWi4UXXniBadOmWY/Vq1ePxx57jM8//5yvvvqKN954gz///JN8+fIBsHTpUtq1a8fZs2fx8/OjWLFiPPvss4wfPz7VGCwWC2+//Tbjxo0DzELe09OTZcuWaWy5iIjkKhrTLSIikgM1adLEpqgG8PHxsb4ODg62ORYcHExERAQAhw4dolq1ataCG6B+/fokJSVx5MgRLBYLZ8+epVmzZveMoWrVqtbX+fLlw9vbmwsXLjzoI4mIiGRLKrpFRERyoHz58qXo7p1R8ubNm6bzXF1dbd5bLBaSkpIyIyQRERGHpTHdIiIiudDWrVtTvK9QoQIAFSpUYM+ePcTGxlqPb9q0CScnJ8qVK4eXlxclSpRg9erVWRqziIhIdqSWbhERkRwoLi6OyMhIm30uLi4ULlwYgDlz5lCrVi0aNGjADz/8wPbt2/nmm28A6NGjB6NGjaJXr16MHj2aixcvMmjQIJ555hn8/PwAGD16NC+88AK+vr60atWKq1evsmnTJgYNGpS1DyoiIuLgVHSLiIjkQMuXL6do0aI2+8qVK8fhw4cBc2bxn376iRdffJGiRYvy448/UrFiRQA8PDxYsWIFL7/8MrVr18bDw4NOnToxefJk67V69erFzZs3+eijj3jttdcoXLgwTz31VNY9oIiISDah2ctFRERyGYvFwvz58+nQoYO9QxEREcnxNKZbREREREREJJOo6BYRERERERHJJBrTLSIikstoZJmIiEjWUUu3iIiIiIiISCZR0S0iIiIiIiKSSVR0i4iIiIiIiGQSFd0iIiIiIiIimURFt4iIiIiIiEgmUdEtIiIiIiIikklUdIuIiIiIiIhkEhXdIiIiIiIiIplERbeIiIiIiIhIJvl//ay+ZWgrCpkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate\n",
    "train_predictions = model.predict(X_train_reordered)\n",
    "accuracy = np.mean(train_predictions == y_train)\n",
    "print(f\"Train Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test_reordered)\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot convergence\n",
    "fig = model.plot_convergence()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9775\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(C = 1.0, kernel='rbf')\n",
    "\n",
    "svm.fit(X_train_reordered, y_train)\n",
    "print(svm.score(X_train_reordered, y_train))\n",
    "\n",
    "print(svm.score(X_test_reordered, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Extract NumPy arrays\n",
    "X_train = train_dataset.data.numpy()  # Shape: (60000, 28, 28)\n",
    "y_train = train_dataset.targets.numpy()\n",
    "X_test = test_dataset.data.numpy()    # Shape: (10000, 28, 28)\n",
    "y_test = test_dataset.targets.numpy()\n",
    "\n",
    "# Filter for binary classes (e.g., 0 vs 1)\n",
    "train_mask = (y_train == 8) | (y_train == 9)\n",
    "test_mask = (y_test == 8) | (y_test == 9)\n",
    "X_train_bin = X_train[train_mask].reshape(-1, 28*28)\n",
    "y_train_bin_orig = y_train[train_mask]\n",
    "X_test_bin = X_test[test_mask].reshape(-1, 28*28)\n",
    "y_test_bin_orig = y_test[test_mask]\n",
    "\n",
    "# Shuffle training data\n",
    "rng = np.random.RandomState(12)  # For reproducibility\n",
    "shuffle_idx = rng.permutation(len(X_train_bin))\n",
    "X_train_bin = X_train_bin[shuffle_idx]\n",
    "y_train_bin_orig = y_train_bin_orig[shuffle_idx]  # Shuffle the original labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class OptimizedBSpline(nn.Module):\n",
    "    \"\"\"Optimized B-spline with iterative De Boor algorithm\"\"\"\n",
    "    def __init__(self, knots, degree=3):\n",
    "        super().__init__()\n",
    "        self.knots = knots\n",
    "        self.degree = degree\n",
    "        self.n_knots = len(knots)\n",
    "\n",
    "    def _find_interval(self, t):\n",
    "        \"\"\"Find the knot interval index for each t value\"\"\"\n",
    "        # Clamp t to valid range and find interval using searchsorted\n",
    "        t_clamped = torch.clamp(t, self.knots[self.degree], self.knots[self.n_knots - self.degree - 1])\n",
    "        i = torch.searchsorted(self.knots, t_clamped, right=True) - 1\n",
    "        # Ensure i stays within valid bounds for degree-k spline\n",
    "        return torch.clamp(i, self.degree, self.n_knots - self.degree - 1)\n",
    "\n",
    "    def forward(self, t, control_points):\n",
    "        \"\"\"Iterative De Boor algorithm for B-spline evaluation\"\"\"\n",
    "        batch_size = t.shape[0]\n",
    "        n_control = len(control_points)\n",
    "        k = self.degree\n",
    "\n",
    "        # Find knot interval for each t\n",
    "        interval = self._find_interval(t)  # Shape: [batch_size]\n",
    "\n",
    "        # Initialize temporary control points for each t\n",
    "        d = torch.zeros(batch_size, k + 1, device=t.device, dtype=t.dtype)\n",
    "        for j in range(k + 1):\n",
    "            idx = torch.clamp(interval - k + j, 0, n_control - 1)\n",
    "            d[:, j] = control_points[idx]\n",
    "\n",
    "        # Iterative De Boor computation\n",
    "        for r in range(1, k + 1):\n",
    "            for j in range(k, r - 1, -1):\n",
    "                left_knot = self.knots[interval - k + j]\n",
    "                right_knot = self.knots[interval - k + j + r]\n",
    "                alpha = (t - left_knot) / (right_knot - left_knot + 1e-8)  # Add epsilon for stability\n",
    "                d[:, j] = (1 - alpha) * d[:, j - 1] + alpha * d[:, j]\n",
    "\n",
    "        return d[:, k]  # Final value for each t\n",
    "\n",
    "class OptimizedTorchCubicSpline(nn.Module):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.y = nn.Parameter(y)\n",
    "        n = len(x)\n",
    "        self.register_buffer('knots', torch.cat([x[0].repeat(3), x[1:-1], x[-1].repeat(3)]))\n",
    "        self.bspline = OptimizedBSpline(self.knots, degree=3)\n",
    "        self.x_min = x[0]\n",
    "        self.x_max = x[-1]\n",
    "\n",
    "    def forward(self, t):\n",
    "        return self.bspline(torch.clamp(t, self.x_min, self.x_max), self.y)\n",
    "\n",
    "class OptimizedDifferentiablePchip(nn.Module):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.y = nn.Parameter(y)\n",
    "        self.n = len(x) - 1\n",
    "\n",
    "    def _compute_derivatives(self, y):\n",
    "        dy = y[1:] - y[:-1]\n",
    "        dx = self.x[1:] - self.x[:-1]\n",
    "        slopes = dy / dx\n",
    "        d = torch.zeros_like(y)\n",
    "        for i in range(1, len(y)-1):\n",
    "            if slopes[i-1] * slopes[i] > 0:\n",
    "                w1 = 2*dx[i] + dx[i-1]\n",
    "                w2 = dx[i] + 2*dx[i-1]\n",
    "                d[i] = (w1 + w2) / (w1/slopes[i-1] + w2/slopes[i])\n",
    "        d[0] = slopes[0]\n",
    "        d[-1] = slopes[-1]\n",
    "        return d\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = t.contiguous()\n",
    "        idx = torch.clamp(torch.searchsorted(self.x, t) - 1, 0, self.n - 1)\n",
    "        x0 = self.x[idx]\n",
    "        x1 = self.x[idx + 1]\n",
    "        y0 = self.y[idx]\n",
    "        y1 = self.y[idx + 1]\n",
    "        t_norm = (t - x0) / (x1 - x0)\n",
    "        d = self._compute_derivatives(self.y)\n",
    "        d0 = d[idx]\n",
    "        d1 = d[idx + 1]\n",
    "        t2 = t_norm * t_norm\n",
    "        t3 = t2 * t_norm\n",
    "        h00 = 2*t3 - 3*t2 + 1\n",
    "        h10 = t3 - 2*t2 + t_norm\n",
    "        h01 = -2*t3 + 3*t2\n",
    "        h11 = t3 - t2\n",
    "        dx_segment = x1 - x0\n",
    "        return h00 * y0 + h10 * dx_segment * d0 + h01 * y1 + h11 * dx_segment * d1\n",
    "\n",
    "class OptimizedPyTorchGradientSMPA(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, learning_rate=0.05, epochs=100, random_state=7, verbose=False,\n",
    "                 lambda_reg=0.0001, patience=10, decay_factor=0.9, min_learning_rate=1e-6,\n",
    "                 n_control_points=6, smoothing_factor=0.0001, spline_type='cubic',\n",
    "                 device=None, track_history=False, optimizer_type='adam', scheduler_type='reduce_on_plateau'):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.initial_learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.patience = patience\n",
    "        self.decay_factor = decay_factor\n",
    "        self.min_learning_rate = min_learning_rate\n",
    "        self.n_control_points = n_control_points\n",
    "        self.smoothing_factor = smoothing_factor\n",
    "        self.spline_type = spline_type\n",
    "        self.device = device if device is not None else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.track_history = track_history\n",
    "        self.optimizer_type = optimizer_type\n",
    "        self.scheduler_type = scheduler_type\n",
    "\n",
    "        if spline_type not in ['cubic', 'pchip']:\n",
    "            raise ValueError(\"spline_type must be 'cubic' or 'pchip'\")\n",
    "        torch.manual_seed(random_state)\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    def _to_tensor(self, data, dtype=torch.float32):\n",
    "        if isinstance(data, torch.Tensor):\n",
    "            return data.to(self.device, dtype=dtype, non_blocking=True)\n",
    "        return torch.tensor(data, dtype=dtype, device=self.device)\n",
    "\n",
    "    def _calculate_class_means(self, X, y):\n",
    "        mask_1 = y == 1\n",
    "        self.m1 = torch.mean(X[mask_1], dim=0)\n",
    "        self.m0 = torch.mean(X[~mask_1], dim=0)\n",
    "\n",
    "    def _initialize_control_points(self, X):\n",
    "        n_features = X.shape[1] - 1\n",
    "        self.spline_models = nn.ModuleList()\n",
    "        for i in range(n_features):\n",
    "            x_min, x_max = X[:, i].min().item(), X[:, i].max().item()\n",
    "            control_x = torch.linspace(x_min, x_max, self.n_control_points, device=self.device)\n",
    "            y_min, y_max = X[:, -1].min().item(), X[:, -1].max().item()\n",
    "            y_mid = (self.m0[-1] + self.m1[-1]) / 2\n",
    "            y_range = y_max - y_min\n",
    "            control_y = torch.empty(self.n_control_points, device=self.device).uniform_(\n",
    "                y_mid - y_range * 0.05, y_mid + y_range * 0.05\n",
    "            )\n",
    "            if self.spline_type == 'cubic':\n",
    "                spline = OptimizedTorchCubicSpline(control_x, control_y).to(self.device)\n",
    "            else:\n",
    "                spline = OptimizedDifferentiablePchip(control_x, control_y).to(self.device)\n",
    "            self.spline_models.append(spline)\n",
    "        self.initial_control_points = [(m.x.clone(), m.y.clone()) for m in self.spline_models]\n",
    "\n",
    "    def _calculate_displacement(self, X):\n",
    "        total_spline = sum(spline(X[:, i]) for i, spline in enumerate(self.spline_models))\n",
    "        return X[:, -1] - total_spline\n",
    "\n",
    "    def _update_pseudo_labels(self, X, y):\n",
    "        m1_displacement = self._calculate_displacement(self.m1.unsqueeze(0))[0]\n",
    "        self.class_1_pseudo = 1 if m1_displacement > 0 else -1\n",
    "        self.class_0_pseudo = -self.class_1_pseudo\n",
    "        return torch.where(y == 1, self.class_1_pseudo, self.class_0_pseudo)\n",
    "\n",
    "    def _create_optimizer_and_scheduler(self):\n",
    "        params = [p for spline in self.spline_models for p in spline.parameters()]\n",
    "        if self.optimizer_type.lower() == 'adam':\n",
    "            optimizer = torch.optim.Adam(params, lr=self.initial_learning_rate)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(params, lr=self.initial_learning_rate)\n",
    "        if self.scheduler_type.lower() == 'reduce_on_plateau':\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode='min', factor=self.decay_factor,\n",
    "                patience=self.patience, min_lr=self.min_learning_rate)\n",
    "        elif self.scheduler_type.lower() == 'step':\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "                optimizer, step_size=self.patience, gamma=self.decay_factor\n",
    "            )\n",
    "        else:\n",
    "            scheduler = None\n",
    "        return optimizer, scheduler\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        try:\n",
    "            l = np.unique(y)\n",
    "            if len(l) != 2:\n",
    "                raise ValueError(\"Algorithm for binary classification only.\")\n",
    "\n",
    "            if X.shape[1] < 2:\n",
    "                raise ValueError(\"At least 2 features required\")\n",
    "\n",
    "            self.label_mapping = {l[0] : 0, l[1] : 1}\n",
    "\n",
    "            y = np.where(y == l[0], 0, 1)\n",
    "\n",
    "            X_tensor = self._to_tensor(X)\n",
    "            y_tensor = self._to_tensor(y, dtype=torch.long)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                self._calculate_class_means(X_tensor, y_tensor)\n",
    "                self._initialize_control_points(X_tensor)\n",
    "\n",
    "            optimizer, scheduler = self._create_optimizer_and_scheduler()\n",
    "\n",
    "            best_error = float('inf')\n",
    "            best_control_ys = [spline.y.clone() for spline in self.spline_models]\n",
    "            best_class_1_pseudo = None\n",
    "\n",
    "            if self.track_history:\n",
    "                self.error_history_ = []\n",
    "                self.control_point_history = [self.initial_control_points]\n",
    "\n",
    "            for epoch in range(self.epochs):\n",
    "                pseudo_labels = self._update_pseudo_labels(X_tensor, y_tensor)\n",
    "                displacements = self._calculate_displacement(X_tensor)\n",
    "\n",
    "                errors = displacements * pseudo_labels <= 0\n",
    "                error_count = errors.sum().item()\n",
    "\n",
    "                if self.verbose and epoch % 5 == 0:\n",
    "                    current_lr = optimizer.param_groups[0]['lr']\n",
    "                    print(f\"Epoch {epoch}: Errors = {error_count}, LR = {current_lr:.6f}\")\n",
    "\n",
    "                if error_count < best_error:\n",
    "                    best_error = error_count\n",
    "                    best_control_ys = [spline.y.clone() for spline in self.spline_models]\n",
    "                    best_class_1_pseudo = self.class_1_pseudo\n",
    "                    self.best_epoch = epoch\n",
    "                    if error_count == 0 and epoch > 10:\n",
    "                        if self.verbose:\n",
    "                            print(f\"Perfect separation achieved at epoch {epoch}\")\n",
    "                        break\n",
    "\n",
    "                if self.track_history:\n",
    "                    self.error_history_.append(error_count)\n",
    "                    self.control_point_history.append(\n",
    "                        [(s.x.clone().cpu().numpy(), s.y.clone().detach().cpu().numpy())\n",
    "                        for s in self.spline_models]\n",
    "                    )\n",
    "\n",
    "                if error_count == 0:\n",
    "                    continue\n",
    "\n",
    "                error_indices = torch.where(errors)[0]\n",
    "                X_err = X_tensor[error_indices]\n",
    "                y_err = y_tensor[error_indices]\n",
    "                ti = torch.where(y_err == 1, 1, -1)\n",
    "\n",
    "                spline_values = sum(spline(X_err[:, i]) for i, spline in enumerate(self.spline_models))\n",
    "                loss = torch.mean(torch.relu(1.0 - ti * self.class_1_pseudo * (X_err[:, -1] - spline_values)))\n",
    "\n",
    "                if self.lambda_reg > 0:\n",
    "                    smoothness_penalty = 0\n",
    "                    for spline in self.spline_models:\n",
    "                        y_diff = spline.y[1:] - spline.y[:-1]\n",
    "                        x_diff = spline.x[1:] - spline.x[:-1]\n",
    "                        smoothness_penalty += torch.mean((y_diff / (x_diff + 1e-8))**2)\n",
    "                    loss += self.lambda_reg * smoothness_penalty\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if scheduler is None:\n",
    "                    if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                        scheduler.step(error_count)\n",
    "                    else:\n",
    "                        scheduler.step()\n",
    "                    if optimizer.param_groups[0]['lr'] <= self.min_learning_rate:\n",
    "                        if self.verbose:\n",
    "                            print(f\"Minimum learning rate reached at epoch {epoch}\")\n",
    "                        break\n",
    "\n",
    "            for spline, best_y in zip(self.spline_models, best_control_ys):\n",
    "                spline.y.data = best_y\n",
    "            self.class_1_pseudo = best_class_1_pseudo\n",
    "        except Exception as e:\n",
    "            print(f\"Error in SMPA fit: {str(e)}\", flush=True)\n",
    "            import traceback\n",
    "            traceback.print_exc(flush=True)\n",
    "            raise  # Re-raise the exception to be caught by parent\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_tensor = self._to_tensor(X)\n",
    "        displacements = self._calculate_displacement(X_tensor)\n",
    "        predictions = torch.where(displacements > 0,\n",
    "                                torch.tensor(1 if self.class_1_pseudo > 0 else 0, device=self.device),\n",
    "                                torch.tensor(0 if self.class_1_pseudo > 0 else 1, device=self.device))\n",
    "\n",
    "        # Convert predictions to numpy\n",
    "        pred_numpy = predictions.cpu().numpy()\n",
    "\n",
    "        # Create reverse mapping from 0 and 1 back to original labels\n",
    "        reverse_mapping = {v: k for k, v in self.label_mapping.items()}\n",
    "\n",
    "        # Map the predictions back to original labels\n",
    "        original_predictions = np.array([reverse_mapping[p] for p in pred_numpy])\n",
    "\n",
    "        return original_predictions\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_tensor = self._to_tensor(X)\n",
    "        displacements = self._calculate_displacement(X_tensor)\n",
    "        raw_probs = 1 / (1 + torch.exp(-displacements * self.class_1_pseudo * 0.5))\n",
    "        if self.class_1_pseudo > 0:\n",
    "            probs = torch.column_stack([1 - raw_probs, raw_probs])\n",
    "        else:\n",
    "            probs = torch.column_stack([raw_probs, 1 - raw_probs])\n",
    "        return probs.cpu().detach().numpy()\n",
    "\n",
    "    def plot_convergence(self, figsize=(10, 4)):\n",
    "        if not self.track_history or not hasattr(self, 'error_history_'):\n",
    "            print(\"Convergence plotting requires track_history=True and a fitted model.\")\n",
    "            return None\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax.plot(self.error_history_, 'b-', label='Errors')\n",
    "        ax.set_title('Error Convergence')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Number of Errors')\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in SMPA fit: The shape of the mask [11800] at index 0 does not match the shape of the indexed tensor [800, 4] at index 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "print_exc() got an unexpected keyword argument 'flush'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 203\u001b[0m, in \u001b[0;36mOptimizedPyTorchGradientSMPA.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_class_means\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_control_points(X_tensor)\n",
      "Cell \u001b[0;32mIn[24], line 136\u001b[0m, in \u001b[0;36mOptimizedPyTorchGradientSMPA._calculate_class_means\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    135\u001b[0m mask_1 \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask_1\u001b[49m\u001b[43m]\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(X[\u001b[38;5;241m~\u001b[39mmask_1], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [11800] at index 0 does not match the shape of the indexed tensor [800, 4] at index 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m OptimizedPyTorchGradientSMPA(\n\u001b[1;32m      2\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.005\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      3\u001b[0m     spline_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpchip\u001b[39m\u001b[38;5;124m'\u001b[39m, track_history\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, lambda_reg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00001\u001b[39m\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_reordered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_bin_orig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 283\u001b[0m, in \u001b[0;36mOptimizedPyTorchGradientSMPA.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in SMPA fit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     \u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_exc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflush\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# Re-raise the exception to be caught by parent\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: print_exc() got an unexpected keyword argument 'flush'"
     ]
    }
   ],
   "source": [
    "model = OptimizedPyTorchGradientSMPA(\n",
    "    learning_rate=0.005, epochs=200, random_state=12, verbose=True,\n",
    "    spline_type='pchip', track_history=True, lambda_reg=0.00001\n",
    ")\n",
    "model.fit(X_train_reordered, y_train_bin_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
